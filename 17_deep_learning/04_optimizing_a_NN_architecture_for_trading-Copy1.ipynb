{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Deep NN to predict Asset Price returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, we need to explore variations of the design options outlined above because we can rarely be sure from the outset which network architecture best suits the data.\n",
    "\n",
    "In this section, we will explore various options to build a simple feedforward Neural Network to predict asset price returns for a one-day horizon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:38.291434Z",
     "start_time": "2021-02-23T05:45:38.289510Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:39.954191Z",
     "start_time": "2021-02-23T05:45:38.293938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, sys\n",
    "from ast import literal_eval as make_tuple\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import spearmanr\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:39.958084Z",
     "start_time": "2021-02-23T05:45:39.955234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print('Using GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:39.968456Z",
     "start_time": "2021-02-23T05:45:39.959253Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from utils import MultipleTimeSeriesCV, format_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:39.992331Z",
     "start_time": "2021-02-23T05:45:39.969458Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "sns.set_style('whitegrid')\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:40.004488Z",
     "start_time": "2021-02-23T05:45:39.993389Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_STORE = '../data/assets.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:40.012549Z",
     "start_time": "2021-02-23T05:45:40.006305Z"
    }
   },
   "outputs": [],
   "source": [
    "results_path = Path('results')\n",
    "if not results_path.exists():\n",
    "    results_path.mkdir()\n",
    "    \n",
    "checkpoint_path = results_path / 'logs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a stock return series to predict asset price moves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To develop our trading strategy, we use the daily stock returns for some 995 US stocks for the eight year period from 2010 to 2017, and the features developed in Chapter 12 that include volatility and momentum factors as well as lagged returns with cross-sectional and sectoral rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:42.078013Z",
     "start_time": "2021-02-23T05:45:40.014012Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_hdf('../12_gradient_boosting_machines/data.h5', 'model_data').dropna().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 1906943 entries, ('A', Timestamp('2010-04-06 00:00:00')) to ('UDR', Timestamp('2017-11-29 00:00:00'))\n",
      "Data columns (total 34 columns):\n",
      " #   Column           Non-Null Count    Dtype  \n",
      "---  ------           --------------    -----  \n",
      " 0   dollar_vol       1906943 non-null  float64\n",
      " 1   dollar_vol_rank  1906943 non-null  float64\n",
      " 2   rsi              1906943 non-null  float64\n",
      " 3   bb_high          1906943 non-null  float64\n",
      " 4   bb_low           1906943 non-null  float64\n",
      " 5   NATR             1906943 non-null  float64\n",
      " 6   ATR              1906943 non-null  float64\n",
      " 7   PPO              1906943 non-null  float64\n",
      " 8   MACD             1906943 non-null  float64\n",
      " 9   sector           1906943 non-null  int32  \n",
      " 10  r01              1906943 non-null  float64\n",
      " 11  r05              1906943 non-null  float64\n",
      " 12  r10              1906943 non-null  float64\n",
      " 13  r21              1906943 non-null  float64\n",
      " 14  r42              1906943 non-null  float64\n",
      " 15  r63              1906943 non-null  float64\n",
      " 16  r01dec           1906943 non-null  float64\n",
      " 17  r05dec           1906943 non-null  float64\n",
      " 18  r10dec           1906943 non-null  float64\n",
      " 19  r21dec           1906943 non-null  float64\n",
      " 20  r42dec           1906943 non-null  float64\n",
      " 21  r63dec           1906943 non-null  float64\n",
      " 22  r01q_sector      1906943 non-null  float64\n",
      " 23  r05q_sector      1906943 non-null  float64\n",
      " 24  r10q_sector      1906943 non-null  float64\n",
      " 25  r21q_sector      1906943 non-null  float64\n",
      " 26  r42q_sector      1906943 non-null  float64\n",
      " 27  r63q_sector      1906943 non-null  float64\n",
      " 28  r01_fwd          1906943 non-null  float64\n",
      " 29  r05_fwd          1906943 non-null  float64\n",
      " 30  r21_fwd          1906943 non-null  float64\n",
      " 31  year             1906943 non-null  int64  \n",
      " 32  month            1906943 non-null  int64  \n",
      " 33  weekday          1906943 non-null  int64  \n",
      "dtypes: float64(30), int32(1), int64(3)\n",
      "memory usage: 495.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:42.090238Z",
     "start_time": "2021-02-23T05:45:42.079584Z"
    }
   },
   "outputs": [],
   "source": [
    "outcomes = data.filter(like='fwd').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:42.105424Z",
     "start_time": "2021-02-23T05:45:42.091504Z"
    }
   },
   "outputs": [],
   "source": [
    "lookahead = 1\n",
    "outcome= f'r{lookahead:02}_fwd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:43.061968Z",
     "start_time": "2021-02-23T05:45:42.106337Z"
    }
   },
   "outputs": [],
   "source": [
    "X_cv = data.loc[idx[:, :'2017'], :].drop(outcomes, axis=1)\n",
    "y_cv = data.loc[idx[:, :'2017'], outcome]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:43.160579Z",
     "start_time": "2021-02-23T05:45:43.063097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "993"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_cv.index.get_level_values('symbol').unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:43.269555Z",
     "start_time": "2021-02-23T05:45:43.161556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 1906943 entries, ('A', Timestamp('2010-04-06 00:00:00')) to ('UDR', Timestamp('2017-11-29 00:00:00'))\n",
      "Data columns (total 31 columns):\n",
      " #   Column           Non-Null Count    Dtype  \n",
      "---  ------           --------------    -----  \n",
      " 0   dollar_vol       1906943 non-null  float64\n",
      " 1   dollar_vol_rank  1906943 non-null  float64\n",
      " 2   rsi              1906943 non-null  float64\n",
      " 3   bb_high          1906943 non-null  float64\n",
      " 4   bb_low           1906943 non-null  float64\n",
      " 5   NATR             1906943 non-null  float64\n",
      " 6   ATR              1906943 non-null  float64\n",
      " 7   PPO              1906943 non-null  float64\n",
      " 8   MACD             1906943 non-null  float64\n",
      " 9   sector           1906943 non-null  int32  \n",
      " 10  r01              1906943 non-null  float64\n",
      " 11  r05              1906943 non-null  float64\n",
      " 12  r10              1906943 non-null  float64\n",
      " 13  r21              1906943 non-null  float64\n",
      " 14  r42              1906943 non-null  float64\n",
      " 15  r63              1906943 non-null  float64\n",
      " 16  r01dec           1906943 non-null  float64\n",
      " 17  r05dec           1906943 non-null  float64\n",
      " 18  r10dec           1906943 non-null  float64\n",
      " 19  r21dec           1906943 non-null  float64\n",
      " 20  r42dec           1906943 non-null  float64\n",
      " 21  r63dec           1906943 non-null  float64\n",
      " 22  r01q_sector      1906943 non-null  float64\n",
      " 23  r05q_sector      1906943 non-null  float64\n",
      " 24  r10q_sector      1906943 non-null  float64\n",
      " 25  r21q_sector      1906943 non-null  float64\n",
      " 26  r42q_sector      1906943 non-null  float64\n",
      " 27  r63q_sector      1906943 non-null  float64\n",
      " 28  year             1906943 non-null  int64  \n",
      " 29  month            1906943 non-null  int64  \n",
      " 30  weekday          1906943 non-null  int64  \n",
      "dtypes: float64(27), int32(1), int64(3)\n",
      "memory usage: 451.7+ MB\n"
     ]
    }
   ],
   "source": [
    "X_cv.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automate model generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following `make_model` function illustrates how to flexibly define various architectural elements for the search process. The dense_layers argument defines both the depth and width of the network as a list of integers. We also use dropout for regularization, expressed as a float in the range [0, 1] to define the probability that a given unit will be excluded from a training iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:43.275796Z",
     "start_time": "2021-02-23T05:45:43.271059Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_model(dense_layers, activation, dropout):\n",
    "    '''Creates a multi-layer perceptron model\n",
    "    \n",
    "    dense_layers: List of layer sizes; one number per layer\n",
    "    '''\n",
    "\n",
    "    model = Sequential()\n",
    "    for i, layer_size in enumerate(dense_layers, 1):\n",
    "        if i == 1:\n",
    "            model.add(Dense(layer_size, input_dim=X_cv.shape[1]))\n",
    "            model.add(Activation(activation))\n",
    "        else:\n",
    "            model.add(Dense(layer_size))\n",
    "            model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer='Adam')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validate multiple configurations with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into a training set for cross-validation, and keep the last 12 months with data as holdout test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:43.289179Z",
     "start_time": "2021-02-23T05:45:43.277271Z"
    }
   },
   "outputs": [],
   "source": [
    "n_splits = 12\n",
    "train_period_length=21 * 12 * 4\n",
    "test_period_length=21 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:43.297459Z",
     "start_time": "2021-02-23T05:45:43.290410Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                          train_period_length=train_period_length,\n",
    "                          test_period_length=test_period_length,\n",
    "                          lookahead=lookahead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define CV Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just need to define our Keras classifier using the make_model function, set cross-validation (see chapter 6 on The Machine Learning Process and following for the OneStepTimeSeriesSplit), and the parameters that we would like to explore. \n",
    "\n",
    "We pick several one- and two-layer configurations, relu and tanh activation functions, and different dropout rates. We could also try out different optimizers (but did not run this experiment to limit what is already a computationally intensive effort):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:43.305908Z",
     "start_time": "2021-02-23T05:45:43.298464Z"
    }
   },
   "outputs": [],
   "source": [
    "dense_layer_opts = [(16, 8), (32, 16), (32, 32), (64, 32)]\n",
    "activation_opts = ['tanh']\n",
    "dropout_opts = [0, .1, .2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:43.314388Z",
     "start_time": "2021-02-23T05:45:43.307047Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = list(product(dense_layer_opts, activation_opts, dropout_opts))\n",
    "np.random.shuffle(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:43.324946Z",
     "start_time": "2021-02-23T05:45:43.315355Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To trigger the parameter search, we instantiate a GridSearchCV object, define the fit_params that will be passed to the Keras modelâ€™s fit method, and provide the training data to the GridSearchCV fit method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:43.332302Z",
     "start_time": "2021-02-23T05:45:43.326769Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_train_valid_data(X, y, train_idx, test_idx):\n",
    "    x_train, y_train = X.iloc[train_idx, :], y.iloc[train_idx]\n",
    "    x_val, y_val = X.iloc[test_idx, :], y.iloc[test_idx]\n",
    "    return x_train, y_train, x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.397856Z",
     "start_time": "2021-02-23T05:45:43.333668Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 32) tanh 0.1 64\n",
      "00:01:07 01 | 01 | -0.0133 | -0.0232\n",
      "00:02:08 01 | 02 |  0.0012 | -0.0050\n",
      "00:03:11 01 | 03 |  0.0143 | -0.0005\n",
      "00:04:10 01 | 04 |  0.0078 | -0.0008\n",
      "00:05:09 01 | 05 |  0.0113 |  0.0183\n",
      "00:06:09 01 | 06 |  0.0114 |  0.0060\n",
      "00:07:08 01 | 07 |  0.0153 |  0.0095\n",
      "00:08:07 01 | 08 |  0.0210 |  0.0318\n",
      "00:09:06 01 | 09 |  0.0102 |  0.0175\n",
      "00:10:06 01 | 10 |  0.0049 |  0.0217\n",
      "00:11:06 01 | 11 |  0.0103 |  0.0165\n",
      "00:12:07 01 | 12 |  0.0164 |  0.0220\n",
      "00:13:08 01 | 13 |  0.0136 |  0.0150\n",
      "00:13:56 01 | 14 |  0.0016 |  0.0095\n",
      "00:14:26 01 | 15 |  0.0071 |  0.0136\n",
      "00:14:57 01 | 16 |  0.0058 |  0.0068\n",
      "00:15:29 01 | 17 |  0.0219 |  0.0130\n",
      "00:15:59 01 | 18 |  0.0045 |  0.0065\n",
      "00:16:30 01 | 19 | -0.0064 | -0.0101\n",
      "00:17:00 01 | 20 |  0.0014 | -0.0010\n",
      "00:17:33 02 | 01 |  0.0010 |  0.0058\n",
      "00:18:03 02 | 02 |  0.0126 |  0.0069\n",
      "00:18:34 02 | 03 | -0.0057 |  0.0011\n",
      "00:19:05 02 | 04 | -0.0110 | -0.0062\n",
      "00:19:36 02 | 05 |  0.0146 |  0.0268\n",
      "00:20:07 02 | 06 | -0.0037 |  0.0028\n",
      "00:20:37 02 | 07 |  0.0186 |  0.0052\n",
      "00:21:08 02 | 08 |  0.0017 | -0.0007\n",
      "00:21:38 02 | 09 | -0.0166 | -0.0116\n",
      "00:22:08 02 | 10 | -0.0066 | -0.0132\n",
      "00:22:39 02 | 11 | -0.0040 | -0.0022\n",
      "00:23:09 02 | 12 |  0.0087 |  0.0093\n",
      "00:23:39 02 | 13 |  0.0028 | -0.0070\n",
      "00:24:09 02 | 14 |  0.0091 |  0.0147\n",
      "00:24:39 02 | 15 |  0.0002 |  0.0006\n",
      "00:25:09 02 | 16 | -0.0042 | -0.0195\n",
      "00:25:39 02 | 17 | -0.0060 | -0.0086\n",
      "00:26:09 02 | 18 |  0.0010 | -0.0006\n",
      "00:26:39 02 | 19 |  0.0018 | -0.0031\n",
      "00:27:09 02 | 20 |  0.0152 |  0.0230\n",
      "00:27:40 03 | 01 | -0.0186 | -0.0361\n",
      "00:28:10 03 | 02 | -0.0009 | -0.0031\n",
      "00:28:39 03 | 03 | -0.0068 | -0.0343\n",
      "00:29:09 03 | 04 | -0.0229 | -0.0566\n",
      "00:29:38 03 | 05 |  0.0008 |  0.0115\n",
      "00:30:08 03 | 06 |  0.0075 |  0.0066\n",
      "00:30:38 03 | 07 | -0.0031 |  0.0115\n",
      "00:31:08 03 | 08 | -0.0166 | -0.0261\n",
      "00:31:36 03 | 09 | -0.0207 | -0.0495\n",
      "00:32:06 03 | 10 |  0.0032 |  0.0095\n",
      "00:32:35 03 | 11 |  0.0017 |  0.0046\n",
      "00:33:06 03 | 12 |  0.0007 |  0.0023\n",
      "00:33:36 03 | 13 | -0.0057 | -0.0176\n",
      "00:34:05 03 | 14 |  0.0020 | -0.0189\n",
      "00:34:36 03 | 15 | -0.0066 | -0.0041\n",
      "00:35:07 03 | 16 | -0.0094 | -0.0143\n",
      "00:35:38 03 | 17 | -0.0217 | -0.0373\n",
      "00:36:08 03 | 18 | -0.0396 | -0.0658\n",
      "00:36:39 03 | 19 | -0.0164 | -0.0084\n",
      "00:37:11 03 | 20 | -0.0038 | -0.0016\n",
      "00:37:43 04 | 01 |  0.0014 |  0.0021\n",
      "00:38:14 04 | 02 | -0.0323 | -0.0367\n",
      "00:38:45 04 | 03 |  0.0007 |  0.0044\n",
      "00:39:17 04 | 04 | -0.0152 | -0.0265\n",
      "00:39:50 04 | 05 | -0.0155 | -0.0282\n",
      "00:40:21 04 | 06 | -0.0273 | -0.0178\n",
      "00:40:53 04 | 07 |  0.0120 |  0.0082\n",
      "00:41:24 04 | 08 | -0.0036 |  0.0074\n",
      "00:41:55 04 | 09 |  0.0215 |  0.0240\n",
      "00:42:27 04 | 10 |  0.0123 |  0.0211\n",
      "00:42:59 04 | 11 |  0.0070 |  0.0203\n",
      "00:43:31 04 | 12 | -0.0226 | -0.0205\n",
      "00:44:02 04 | 13 |  0.0170 |  0.0221\n",
      "00:44:33 04 | 14 |  0.0190 |  0.0194\n",
      "00:45:04 04 | 15 | -0.0202 | -0.0386\n",
      "00:45:35 04 | 16 |  0.0240 |  0.0185\n",
      "00:46:06 04 | 17 |  0.0028 |  0.0245\n",
      "00:46:36 04 | 18 |  0.0098 |  0.0194\n",
      "00:47:08 04 | 19 | -0.0021 | -0.0110\n",
      "00:47:38 04 | 20 | -0.0335 | -0.0480\n",
      "00:48:11 05 | 01 | -0.0045 |  0.0092\n",
      "00:48:44 05 | 02 | -0.0087 | -0.0069\n",
      "00:49:36 05 | 03 |  0.0041 |  0.0002\n",
      "00:50:34 05 | 04 |  0.0069 |  0.0018\n",
      "00:51:32 05 | 05 |  0.0079 |  0.0128\n",
      "00:52:30 05 | 06 |  0.0174 | -0.0056\n",
      "00:53:20 05 | 07 |  0.0026 |  0.0085\n",
      "00:54:15 05 | 08 |  0.0100 | -0.0003\n",
      "00:55:12 05 | 09 |  0.0057 |  0.0121\n",
      "00:55:57 05 | 10 |  0.0061 |  0.0098\n",
      "00:56:30 05 | 11 |  0.0075 |  0.0042\n",
      "00:57:04 05 | 12 |  0.0115 |  0.0113\n",
      "00:57:50 05 | 13 |  0.0066 |  0.0052\n",
      "00:59:02 05 | 14 |  0.0083 |  0.0124\n",
      "01:00:12 05 | 15 |  0.0017 |  0.0041\n",
      "01:01:24 05 | 16 | -0.0102 | -0.0200\n",
      "01:02:35 05 | 17 |  0.0191 | -0.0025\n",
      "01:03:45 05 | 18 | -0.0030 |  0.0035\n",
      "01:04:55 05 | 19 |  0.0214 |  0.0142\n",
      "01:06:04 05 | 20 |  0.0115 | -0.0064\n",
      "01:07:15 06 | 01 | -0.0144 | -0.0353\n",
      "01:08:24 06 | 02 |  0.0283 |  0.0293\n",
      "01:09:35 06 | 03 |  0.0183 |  0.0335\n",
      "01:10:45 06 | 04 |  0.0373 |  0.0579\n",
      "01:11:56 06 | 05 |  0.0179 |  0.0048\n",
      "01:13:07 06 | 06 |  0.0217 |  0.0137\n",
      "01:14:15 06 | 07 |  0.0018 |  0.0049\n",
      "01:15:25 06 | 08 |  0.0197 |  0.0207\n",
      "01:16:34 06 | 09 |  0.0248 |  0.0307\n",
      "01:17:43 06 | 10 |  0.0218 | -0.0036\n",
      "01:18:52 06 | 11 |  0.0338 |  0.0217\n",
      "01:20:01 06 | 12 |  0.0140 |  0.0218\n",
      "01:21:09 06 | 13 |  0.0072 | -0.0004\n",
      "01:22:16 06 | 14 |  0.0210 |  0.0256\n",
      "01:23:23 06 | 15 |  0.0271 |  0.0155\n",
      "01:24:31 06 | 16 |  0.0358 |  0.0361\n",
      "01:25:39 06 | 17 |  0.0252 |  0.0289\n",
      "01:26:46 06 | 18 |  0.0225 |  0.0413\n",
      "01:27:54 06 | 19 |  0.0287 |  0.0060\n",
      "01:29:02 06 | 20 |  0.0310 |  0.0169\n",
      "01:30:13 07 | 01 |  0.0356 |  0.0390\n",
      "01:31:20 07 | 02 |  0.0386 |  0.0279\n",
      "01:32:27 07 | 03 |  0.0311 |  0.0334\n",
      "01:33:35 07 | 04 | -0.0014 |  0.0282\n",
      "01:34:42 07 | 05 |  0.0437 |  0.0445\n",
      "01:35:49 07 | 06 | -0.0127 | -0.0055\n",
      "01:36:56 07 | 07 |  0.0025 |  0.0157\n",
      "01:38:04 07 | 08 |  0.0356 |  0.0474\n",
      "01:39:10 07 | 09 |  0.0067 |  0.0274\n",
      "01:40:17 07 | 10 |  0.0251 |  0.0225\n",
      "01:41:23 07 | 11 |  0.0143 |  0.0250\n",
      "01:42:30 07 | 12 |  0.0238 |  0.0217\n",
      "01:43:37 07 | 13 |  0.0206 |  0.0572\n",
      "01:44:43 07 | 14 |  0.0092 |  0.0514\n",
      "01:45:50 07 | 15 |  0.0078 |  0.0344\n",
      "01:46:57 07 | 16 |  0.0188 |  0.0113\n",
      "01:48:04 07 | 17 |  0.0231 |  0.0454\n",
      "01:49:10 07 | 18 |  0.0099 |  0.0123\n",
      "01:50:16 07 | 19 |  0.0226 |  0.0404\n",
      "01:51:22 07 | 20 | -0.0047 | -0.0038\n",
      "01:52:29 08 | 01 |  0.0335 |  0.0321\n",
      "01:53:34 08 | 02 |  0.0116 |  0.0235\n",
      "01:54:40 08 | 03 | -0.0031 | -0.0026\n",
      "01:55:47 08 | 04 |  0.0216 |  0.0048\n",
      "01:56:53 08 | 05 | -0.0000 | -0.0069\n",
      "01:57:58 08 | 06 |  0.0032 |  0.0075\n",
      "01:59:04 08 | 07 |  0.0015 |  0.0064\n",
      "02:00:10 08 | 08 |  0.0011 | -0.0019\n",
      "02:01:15 08 | 09 |  0.0104 |  0.0105\n",
      "02:02:21 08 | 10 | -0.0032 |  0.0069\n",
      "02:03:26 08 | 11 | -0.0134 | -0.0199\n",
      "02:04:33 08 | 12 | -0.0083 | -0.0017\n",
      "02:05:38 08 | 13 | -0.0065 |  0.0056\n",
      "02:06:44 08 | 14 | -0.0082 | -0.0062\n",
      "02:07:50 08 | 15 | -0.0106 | -0.0141\n",
      "02:08:55 08 | 16 | -0.0165 | -0.0261\n",
      "02:10:02 08 | 17 | -0.0102 | -0.0104\n",
      "02:11:08 08 | 18 |  0.0068 | -0.0005\n",
      "02:11:58 08 | 19 | -0.0019 |  0.0038\n",
      "02:12:35 08 | 20 | -0.0030 | -0.0090\n",
      "02:13:13 09 | 01 | -0.0017 |  0.0079\n",
      "02:13:48 09 | 02 |  0.0240 |  0.0229\n",
      "02:14:23 09 | 03 |  0.0083 |  0.0014\n",
      "02:14:59 09 | 04 |  0.0175 |  0.0212\n",
      "02:15:34 09 | 05 |  0.0226 | -0.0016\n",
      "02:16:09 09 | 06 |  0.0303 |  0.0440\n",
      "02:16:51 09 | 07 |  0.0274 |  0.0206\n",
      "02:17:39 09 | 08 |  0.0004 |  0.0057\n",
      "02:18:28 09 | 09 | -0.0081 | -0.0175\n",
      "02:19:20 09 | 10 | -0.0059 |  0.0107\n",
      "02:20:12 09 | 11 |  0.0044 | -0.0143\n",
      "02:21:04 09 | 12 | -0.0006 |  0.0080\n",
      "02:21:55 09 | 13 |  0.0086 | -0.0001\n",
      "02:22:47 09 | 14 | -0.0005 | -0.0026\n",
      "02:23:38 09 | 15 |  0.0010 |  0.0032\n",
      "02:24:26 09 | 16 |  0.0033 |  0.0054\n",
      "02:25:14 09 | 17 |  0.0116 |  0.0190\n",
      "02:26:02 09 | 18 |  0.0082 |  0.0116\n",
      "02:26:51 09 | 19 | -0.0085 | -0.0108\n",
      "02:27:39 09 | 20 |  0.0060 |  0.0135\n",
      "02:28:30 10 | 01 | -0.0061 | -0.0093\n",
      "02:29:20 10 | 02 |  0.0092 |  0.0052\n",
      "02:30:11 10 | 03 | -0.0058 | -0.0329\n",
      "02:31:33 10 | 04 |  0.0262 |  0.0108\n",
      "02:33:04 10 | 05 | -0.0007 |  0.0060\n",
      "02:34:33 10 | 06 | -0.0109 | -0.0167\n",
      "02:35:52 10 | 07 | -0.0237 | -0.0211\n",
      "02:36:42 10 | 08 | -0.0095 | -0.0189\n",
      "02:37:33 10 | 09 | -0.0049 | -0.0049\n",
      "02:38:26 10 | 10 |  0.0190 |  0.0142\n",
      "02:39:18 10 | 11 |  0.0165 |  0.0122\n",
      "02:40:10 10 | 12 |  0.0029 |  0.0066\n",
      "02:41:04 10 | 13 | -0.0206 | -0.0333\n",
      "02:41:58 10 | 14 | -0.0180 | -0.0249\n",
      "02:42:52 10 | 15 |  0.0170 |  0.0124\n",
      "02:43:47 10 | 16 |  0.0051 |  0.0044\n",
      "02:44:43 10 | 17 |  0.0119 |  0.0069\n",
      "02:45:37 10 | 18 | -0.0141 | -0.0411\n",
      "02:46:32 10 | 19 |  0.0071 |  0.0050\n",
      "02:47:25 10 | 20 |  0.0136 |  0.0226\n",
      "02:48:18 11 | 01 |  0.0257 |  0.0251\n",
      "02:49:09 11 | 02 |  0.0285 |  0.0297\n",
      "02:50:00 11 | 03 |  0.0160 |  0.0152\n",
      "02:50:49 11 | 04 |  0.0193 |  0.0094\n",
      "02:51:40 11 | 05 |  0.0255 |  0.0171\n",
      "02:52:30 11 | 06 |  0.0089 |  0.0009\n",
      "02:53:19 11 | 07 | -0.0007 | -0.0060\n",
      "02:54:10 11 | 08 |  0.0427 |  0.0369\n",
      "02:55:02 11 | 09 |  0.0343 |  0.0298\n",
      "02:55:55 11 | 10 |  0.0312 |  0.0167\n",
      "02:57:17 11 | 11 |  0.0202 |  0.0185\n",
      "02:58:47 11 | 12 |  0.0260 |  0.0204\n",
      "03:00:17 11 | 13 |  0.0517 |  0.0349\n",
      "03:01:48 11 | 14 |  0.0409 |  0.0365\n",
      "03:03:14 11 | 15 |  0.0354 |  0.0301\n",
      "03:04:42 11 | 16 |  0.0288 |  0.0222\n",
      "03:06:10 11 | 17 |  0.0363 |  0.0318\n",
      "03:07:37 11 | 18 |  0.0317 |  0.0229\n",
      "03:09:05 11 | 19 |  0.0150 |  0.0121\n",
      "03:10:07 11 | 20 |  0.0306 |  0.0242\n",
      "03:10:58 12 | 01 |  0.0246 |  0.0172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03:11:46 12 | 02 |  0.0035 |  0.0080\n",
      "03:12:36 12 | 03 |  0.0051 |  0.0035\n",
      "03:13:26 12 | 04 | -0.0069 | -0.0226\n",
      "03:14:19 12 | 05 | -0.0149 | -0.0139\n",
      "03:15:12 12 | 06 | -0.0010 |  0.0024\n",
      "03:16:03 12 | 07 | -0.0105 |  0.0039\n",
      "03:16:55 12 | 08 | -0.0197 |  0.0017\n",
      "03:17:46 12 | 09 | -0.0167 | -0.0027\n",
      "03:18:37 12 | 10 | -0.0239 | -0.0139\n",
      "03:19:28 12 | 11 | -0.0186 |  0.0007\n",
      "03:20:08 12 | 12 | -0.0318 | -0.0393\n",
      "03:20:36 12 | 13 | -0.0233 | -0.0297\n",
      "03:21:04 12 | 14 | -0.0096 | -0.0172\n",
      "03:21:33 12 | 15 | -0.0217 | -0.0180\n",
      "03:22:02 12 | 16 | -0.0228 | -0.0039\n",
      "03:22:31 12 | 17 | -0.0215 | -0.0211\n",
      "03:23:00 12 | 18 | -0.0159 | -0.0032\n",
      "03:23:38 12 | 19 | -0.0144 | -0.0211\n",
      "03:24:30 12 | 20 | -0.0221 | -0.0189\n",
      "(64, 32) tanh 0.1 256\n",
      "00:00:17 01 | 01 | -0.0026 | -0.0060\n",
      "00:00:31 01 | 02 |  0.0202 |  0.0132\n",
      "00:00:46 01 | 03 |  0.0189 |  0.0266\n",
      "00:00:60 01 | 04 |  0.0084 | -0.0066\n",
      "00:01:14 01 | 05 |  0.0071 | -0.0119\n",
      "00:01:28 01 | 06 | -0.0032 |  0.0026\n",
      "00:01:43 01 | 07 | -0.0125 |  0.0033\n",
      "00:01:57 01 | 08 |  0.0135 |  0.0308\n",
      "00:02:11 01 | 09 |  0.0111 |  0.0186\n",
      "00:02:25 01 | 10 |  0.0152 |  0.0163\n",
      "00:02:40 01 | 11 |  0.0097 |  0.0132\n",
      "00:02:55 01 | 12 |  0.0033 |  0.0162\n",
      "00:03:09 01 | 13 |  0.0101 |  0.0202\n",
      "00:03:24 01 | 14 | -0.0047 | -0.0041\n",
      "00:03:38 01 | 15 | -0.0127 | -0.0229\n",
      "00:03:53 01 | 16 | -0.0069 | -0.0153\n",
      "00:04:07 01 | 17 |  0.0035 |  0.0040\n",
      "00:04:21 01 | 18 | -0.0060 | -0.0186\n",
      "00:04:36 01 | 19 | -0.0136 | -0.0348\n",
      "00:04:50 01 | 20 | -0.0059 | -0.0187\n",
      "00:05:07 02 | 01 |  0.0121 |  0.0249\n",
      "00:05:21 02 | 02 | -0.0177 | -0.0231\n",
      "00:05:36 02 | 03 |  0.0053 |  0.0064\n",
      "00:05:51 02 | 04 | -0.0078 | -0.0047\n",
      "00:06:05 02 | 05 | -0.0185 | -0.0030\n",
      "00:06:20 02 | 06 |  0.0131 |  0.0283\n",
      "00:06:35 02 | 07 |  0.0083 |  0.0084\n",
      "00:06:50 02 | 08 |  0.0155 |  0.0253\n",
      "00:07:04 02 | 09 |  0.0126 |  0.0242\n",
      "00:07:19 02 | 10 |  0.0088 |  0.0025\n",
      "00:07:32 02 | 11 |  0.0134 |  0.0282\n",
      "00:07:45 02 | 12 |  0.0001 | -0.0026\n",
      "00:08:01 02 | 13 |  0.0127 |  0.0154\n",
      "00:08:16 02 | 14 |  0.0181 |  0.0169\n",
      "00:08:31 02 | 15 |  0.0213 |  0.0216\n",
      "00:08:46 02 | 16 |  0.0208 |  0.0205\n",
      "00:09:02 02 | 17 |  0.0120 |  0.0096\n",
      "00:09:16 02 | 18 |  0.0206 |  0.0160\n",
      "00:09:31 02 | 19 |  0.0190 |  0.0319\n",
      "00:09:46 02 | 20 |  0.0024 |  0.0112\n",
      "00:10:02 03 | 01 | -0.0004 |  0.0061\n",
      "00:10:17 03 | 02 | -0.0106 | -0.0187\n",
      "00:10:32 03 | 03 | -0.0039 |  0.0017\n",
      "00:10:46 03 | 04 |  0.0091 |  0.0109\n",
      "00:11:01 03 | 05 |  0.0019 | -0.0036\n",
      "00:11:15 03 | 06 |  0.0247 |  0.0241\n",
      "00:11:30 03 | 07 | -0.0151 | -0.0185\n",
      "00:11:45 03 | 08 | -0.0041 |  0.0031\n",
      "00:12:01 03 | 09 | -0.0063 | -0.0295\n",
      "00:12:16 03 | 10 |  0.0248 |  0.0324\n",
      "00:12:30 03 | 11 | -0.0070 | -0.0129\n",
      "00:12:46 03 | 12 | -0.0047 | -0.0052\n",
      "00:13:01 03 | 13 |  0.0051 |  0.0076\n",
      "00:13:15 03 | 14 |  0.0070 | -0.0153\n",
      "00:13:27 03 | 15 |  0.0120 |  0.0077\n",
      "00:13:41 03 | 16 |  0.0019 | -0.0059\n",
      "00:13:54 03 | 17 | -0.0079 | -0.0176\n",
      "00:14:07 03 | 18 |  0.0181 |  0.0061\n",
      "00:14:20 03 | 19 |  0.0096 |  0.0177\n",
      "00:14:33 03 | 20 |  0.0083 |  0.0037\n",
      "00:14:48 04 | 01 | -0.0159 |  0.0044\n",
      "00:15:01 04 | 02 |  0.0134 |  0.0101\n",
      "00:15:14 04 | 03 |  0.0048 |  0.0042\n",
      "00:15:27 04 | 04 |  0.0379 |  0.0225\n",
      "00:15:39 04 | 05 | -0.0069 | -0.0049\n",
      "00:15:52 04 | 06 |  0.0194 |  0.0314\n",
      "00:16:05 04 | 07 | -0.0102 | -0.0170\n",
      "00:16:19 04 | 08 |  0.0242 |  0.0224\n",
      "00:16:31 04 | 09 |  0.0017 |  0.0062\n",
      "00:16:43 04 | 10 | -0.0272 | -0.0410\n",
      "00:16:55 04 | 11 |  0.0070 | -0.0047\n",
      "00:17:06 04 | 12 | -0.0105 | -0.0171\n",
      "00:17:18 04 | 13 | -0.0029 | -0.0252\n",
      "00:17:30 04 | 14 |  0.0165 |  0.0025\n",
      "00:17:43 04 | 15 |  0.0056 | -0.0095\n",
      "00:17:55 04 | 16 | -0.0068 | -0.0294\n",
      "00:18:07 04 | 17 |  0.0012 | -0.0039\n",
      "00:18:19 04 | 18 |  0.0091 |  0.0042\n",
      "00:18:31 04 | 19 |  0.0011 |  0.0009\n",
      "00:18:43 04 | 20 |  0.0041 |  0.0049\n",
      "00:18:57 05 | 01 |  0.0071 |  0.0258\n",
      "00:19:09 05 | 02 | -0.0165 | -0.0130\n",
      "00:19:29 05 | 03 |  0.0357 |  0.0359\n",
      "00:19:51 05 | 04 | -0.0204 | -0.0376\n",
      "00:20:13 05 | 05 |  0.0079 | -0.0107\n",
      "00:20:36 05 | 06 |  0.0284 |  0.0466\n",
      "00:20:58 05 | 07 | -0.0267 | -0.0344\n",
      "00:21:20 05 | 08 | -0.0183 | -0.0068\n",
      "00:21:42 05 | 09 | -0.0160 | -0.0177\n",
      "00:22:03 05 | 10 | -0.0100 | -0.0041\n",
      "00:22:15 05 | 11 |  0.0064 |  0.0053\n",
      "00:22:27 05 | 12 | -0.0141 | -0.0089\n",
      "00:22:39 05 | 13 | -0.0042 |  0.0022\n",
      "00:22:51 05 | 14 | -0.0055 |  0.0091\n",
      "00:23:03 05 | 15 | -0.0074 |  0.0033\n",
      "00:23:15 05 | 16 | -0.0080 | -0.0094\n",
      "00:23:28 05 | 17 |  0.0007 |  0.0158\n",
      "00:23:39 05 | 18 | -0.0221 | -0.0340\n",
      "00:23:52 05 | 19 |  0.0039 | -0.0008\n",
      "00:24:08 05 | 20 | -0.0106 |  0.0012\n",
      "00:24:32 06 | 01 | -0.0201 | -0.0153\n",
      "00:24:55 06 | 02 |  0.0297 |  0.0162\n",
      "00:25:17 06 | 03 |  0.0439 |  0.0497\n",
      "00:25:40 06 | 04 |  0.0185 |  0.0206\n",
      "00:26:03 06 | 05 |  0.0197 |  0.0088\n",
      "00:26:26 06 | 06 |  0.0068 |  0.0060\n",
      "00:26:49 06 | 07 |  0.0310 |  0.0306\n",
      "00:27:12 06 | 08 | -0.0162 | -0.0163\n",
      "00:27:34 06 | 09 |  0.0114 |  0.0090\n",
      "00:27:57 06 | 10 |  0.0159 |  0.0165\n",
      "00:28:20 06 | 11 |  0.0196 |  0.0099\n",
      "00:28:43 06 | 12 |  0.0157 |  0.0366\n",
      "00:29:06 06 | 13 |  0.0128 |  0.0146\n",
      "00:29:28 06 | 14 |  0.0289 |  0.0251\n",
      "00:29:51 06 | 15 |  0.0168 |  0.0294\n",
      "00:30:14 06 | 16 |  0.0371 |  0.0395\n",
      "00:30:37 06 | 17 |  0.0119 |  0.0230\n",
      "00:30:60 06 | 18 |  0.0216 |  0.0335\n",
      "00:31:24 06 | 19 |  0.0407 |  0.0555\n",
      "00:31:46 06 | 20 |  0.0247 |  0.0302\n",
      "00:32:11 07 | 01 | -0.0102 | -0.0095\n",
      "00:32:34 07 | 02 |  0.0249 |  0.0258\n",
      "00:32:57 07 | 03 | -0.0174 | -0.0193\n",
      "00:33:20 07 | 04 |  0.0274 |  0.0146\n",
      "00:33:44 07 | 05 |  0.0255 |  0.0290\n",
      "00:34:06 07 | 06 |  0.0216 |  0.0481\n",
      "00:34:29 07 | 07 |  0.0320 |  0.0355\n",
      "00:34:52 07 | 08 |  0.0048 | -0.0218\n",
      "00:35:15 07 | 09 |  0.0307 |  0.0298\n",
      "00:35:39 07 | 10 |  0.0268 |  0.0363\n",
      "00:36:01 07 | 11 |  0.0237 |  0.0640\n",
      "00:36:25 07 | 12 |  0.0222 |  0.0538\n",
      "00:36:47 07 | 13 |  0.0137 |  0.0479\n",
      "00:37:10 07 | 14 |  0.0195 |  0.0449\n",
      "00:37:33 07 | 15 |  0.0186 |  0.0387\n",
      "00:37:57 07 | 16 |  0.0078 |  0.0393\n",
      "00:38:20 07 | 17 |  0.0117 |  0.0380\n",
      "00:38:43 07 | 18 |  0.0169 |  0.0277\n",
      "00:39:06 07 | 19 |  0.0139 |  0.0372\n",
      "00:39:29 07 | 20 |  0.0069 |  0.0226\n",
      "00:39:54 08 | 01 | -0.0083 | -0.0058\n",
      "00:40:17 08 | 02 |  0.0256 |  0.0297\n",
      "00:40:40 08 | 03 |  0.0080 |  0.0191\n",
      "00:41:03 08 | 04 |  0.0174 |  0.0200\n",
      "00:41:26 08 | 05 |  0.0244 |  0.0150\n",
      "00:41:48 08 | 06 |  0.0286 |  0.0433\n",
      "00:42:11 08 | 07 |  0.0345 |  0.0434\n",
      "00:42:32 08 | 08 |  0.0132 |  0.0212\n",
      "00:42:55 08 | 09 |  0.0228 |  0.0231\n",
      "00:43:17 08 | 10 |  0.0106 |  0.0155\n",
      "00:43:39 08 | 11 |  0.0199 |  0.0179\n",
      "00:44:02 08 | 12 |  0.0199 |  0.0312\n",
      "00:44:24 08 | 13 |  0.0357 |  0.0137\n",
      "00:44:46 08 | 14 |  0.0165 |  0.0202\n",
      "00:45:08 08 | 15 |  0.0254 |  0.0349\n",
      "00:45:31 08 | 16 |  0.0250 |  0.0308\n",
      "00:45:54 08 | 17 |  0.0145 |  0.0210\n",
      "00:46:17 08 | 18 |  0.0242 |  0.0349\n",
      "00:46:40 08 | 19 |  0.0197 |  0.0218\n",
      "00:47:03 08 | 20 |  0.0173 |  0.0131\n",
      "00:47:28 09 | 01 | -0.0116 | -0.0047\n",
      "00:47:50 09 | 02 |  0.0161 |  0.0138\n",
      "00:48:07 09 | 03 | -0.0066 | -0.0226\n",
      "00:48:24 09 | 04 | -0.0076 |  0.0075\n",
      "00:48:40 09 | 05 |  0.0002 |  0.0123\n",
      "00:48:56 09 | 06 |  0.0196 |  0.0142\n",
      "00:49:13 09 | 07 |  0.0102 |  0.0238\n",
      "00:49:29 09 | 08 | -0.0101 | -0.0088\n",
      "00:49:46 09 | 09 |  0.0004 | -0.0052\n",
      "00:50:01 09 | 10 | -0.0099 | -0.0239\n",
      "00:50:16 09 | 11 | -0.0024 |  0.0055\n",
      "00:50:32 09 | 12 |  0.0149 |  0.0058\n",
      "00:50:47 09 | 13 | -0.0031 |  0.0044\n",
      "00:51:03 09 | 14 |  0.0080 | -0.0090\n",
      "00:51:20 09 | 15 |  0.0184 |  0.0276\n",
      "00:51:36 09 | 16 |  0.0208 |  0.0246\n",
      "00:51:52 09 | 17 |  0.0101 |  0.0180\n",
      "00:52:09 09 | 18 |  0.0143 |  0.0004\n",
      "00:52:25 09 | 19 |  0.0216 |  0.0371\n",
      "00:52:42 09 | 20 |  0.0171 |  0.0118\n",
      "00:53:00 10 | 01 |  0.0168 |  0.0178\n",
      "00:53:16 10 | 02 | -0.0341 | -0.0339\n",
      "00:53:33 10 | 03 | -0.0198 | -0.0159\n",
      "00:53:50 10 | 04 | -0.0232 | -0.0252\n",
      "00:54:06 10 | 05 |  0.0129 |  0.0115\n",
      "00:54:23 10 | 06 |  0.0092 |  0.0025\n",
      "00:54:40 10 | 07 |  0.0413 |  0.0424\n",
      "00:55:01 10 | 08 | -0.0096 | -0.0185\n",
      "00:55:25 10 | 09 | -0.0076 | -0.0132\n",
      "00:55:49 10 | 10 | -0.0359 | -0.0266\n",
      "00:56:13 10 | 11 | -0.0377 | -0.0244\n",
      "00:56:37 10 | 12 | -0.0290 | -0.0213\n",
      "00:57:00 10 | 13 | -0.0098 | -0.0191\n",
      "00:57:24 10 | 14 |  0.0062 |  0.0071\n",
      "00:57:48 10 | 15 | -0.0229 | -0.0395\n",
      "00:58:12 10 | 16 |  0.0307 |  0.0271\n",
      "00:58:35 10 | 17 | -0.0046 |  0.0002\n",
      "00:58:58 10 | 18 | -0.0328 | -0.0403\n",
      "00:59:22 10 | 19 |  0.0130 |  0.0196\n",
      "00:59:46 10 | 20 |  0.0036 | -0.0047\n",
      "01:00:12 11 | 01 | -0.0082 | -0.0197\n",
      "01:00:36 11 | 02 |  0.0174 |  0.0102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:00:60 11 | 03 |  0.0337 |  0.0458\n",
      "01:01:23 11 | 04 |  0.0114 |  0.0216\n",
      "01:01:47 11 | 05 |  0.0180 |  0.0163\n",
      "01:02:11 11 | 06 |  0.0351 |  0.0281\n",
      "01:02:35 11 | 07 |  0.0130 | -0.0046\n",
      "01:02:58 11 | 08 |  0.0153 |  0.0231\n",
      "01:03:22 11 | 09 |  0.0200 |  0.0114\n",
      "01:03:46 11 | 10 |  0.0106 |  0.0060\n",
      "01:04:09 11 | 11 |  0.0409 |  0.0348\n",
      "01:04:34 11 | 12 |  0.0087 |  0.0023\n",
      "01:04:57 11 | 13 |  0.0303 |  0.0282\n",
      "01:05:20 11 | 14 |  0.0055 |  0.0085\n",
      "01:05:43 11 | 15 |  0.0177 |  0.0159\n",
      "01:06:06 11 | 16 |  0.0302 |  0.0405\n",
      "01:06:29 11 | 17 |  0.0178 |  0.0239\n",
      "01:06:53 11 | 18 |  0.0294 |  0.0310\n",
      "01:07:16 11 | 19 |  0.0229 |  0.0258\n",
      "01:07:39 11 | 20 |  0.0284 |  0.0288\n",
      "01:08:04 12 | 01 |  0.0052 |  0.0019\n",
      "01:08:27 12 | 02 |  0.0198 |  0.0282\n",
      "01:08:51 12 | 03 |  0.0340 |  0.0389\n",
      "01:09:14 12 | 04 | -0.0004 | -0.0095\n",
      "01:09:37 12 | 05 |  0.0232 |  0.0189\n",
      "01:09:60 12 | 06 | -0.0062 | -0.0266\n",
      "01:10:23 12 | 07 |  0.0200 | -0.0000\n",
      "01:10:45 12 | 08 |  0.0147 |  0.0128\n",
      "01:11:08 12 | 09 |  0.0090 | -0.0004\n",
      "01:11:31 12 | 10 |  0.0199 |  0.0213\n",
      "01:11:54 12 | 11 |  0.0069 |  0.0373\n",
      "01:12:17 12 | 12 |  0.0299 |  0.0328\n",
      "01:12:40 12 | 13 |  0.0077 | -0.0077\n",
      "01:13:03 12 | 14 |  0.0040 | -0.0103\n",
      "01:13:26 12 | 15 |  0.0135 |  0.0109\n",
      "01:13:50 12 | 16 |  0.0094 | -0.0023\n",
      "01:14:13 12 | 17 |  0.0098 |  0.0162\n",
      "01:14:35 12 | 18 |  0.0125 |  0.0147\n",
      "01:14:59 12 | 19 |  0.0185 |  0.0179\n",
      "01:15:22 12 | 20 |  0.0182 |  0.0364\n",
      "(64, 32) tanh 0 64\n",
      "00:01:18 01 | 01 |  0.0297 |  0.0187\n",
      "00:02:37 01 | 02 |  0.0131 |  0.0152\n",
      "00:03:54 01 | 03 |  0.0233 |  0.0259\n",
      "00:05:12 01 | 04 |  0.0148 |  0.0213\n",
      "00:06:30 01 | 05 |  0.0023 | -0.0017\n",
      "00:07:48 01 | 06 |  0.0269 |  0.0396\n",
      "00:09:06 01 | 07 |  0.0168 |  0.0073\n",
      "00:10:24 01 | 08 |  0.0125 |  0.0237\n",
      "00:11:41 01 | 09 |  0.0141 |  0.0206\n",
      "00:12:59 01 | 10 |  0.0136 |  0.0204\n",
      "00:14:16 01 | 11 |  0.0098 |  0.0167\n",
      "00:15:33 01 | 12 |  0.0079 |  0.0232\n",
      "00:16:51 01 | 13 | -0.0016 |  0.0053\n",
      "00:18:08 01 | 14 |  0.0018 | -0.0129\n",
      "00:19:26 01 | 15 | -0.0071 | -0.0044\n",
      "00:20:43 01 | 16 |  0.0035 | -0.0043\n",
      "00:22:00 01 | 17 |  0.0036 | -0.0041\n",
      "00:23:17 01 | 18 |  0.0274 |  0.0277\n",
      "00:24:35 01 | 19 |  0.0030 |  0.0025\n",
      "00:25:53 01 | 20 |  0.0135 |  0.0194\n",
      "00:27:13 02 | 01 |  0.0071 |  0.0046\n",
      "00:28:31 02 | 02 |  0.0022 | -0.0092\n",
      "00:29:48 02 | 03 |  0.0117 |  0.0107\n",
      "00:31:05 02 | 04 | -0.0162 | -0.0148\n",
      "00:32:23 02 | 05 | -0.0150 | -0.0074\n",
      "00:33:41 02 | 06 | -0.0124 | -0.0125\n",
      "00:34:59 02 | 07 | -0.0037 | -0.0132\n",
      "00:36:17 02 | 08 |  0.0114 |  0.0067\n",
      "00:37:35 02 | 09 | -0.0102 |  0.0075\n",
      "00:38:52 02 | 10 |  0.0188 |  0.0214\n",
      "00:40:10 02 | 11 |  0.0162 |  0.0280\n",
      "00:41:27 02 | 12 |  0.0176 |  0.0290\n",
      "00:42:44 02 | 13 |  0.0230 |  0.0201\n",
      "00:44:03 02 | 14 | -0.0156 | -0.0103\n",
      "00:45:20 02 | 15 |  0.0128 |  0.0149\n",
      "00:46:38 02 | 16 |  0.0122 |  0.0137\n",
      "00:47:55 02 | 17 | -0.0104 | -0.0038\n",
      "00:49:12 02 | 18 | -0.0123 | -0.0061\n",
      "00:50:29 02 | 19 |  0.0126 |  0.0186\n",
      "00:51:46 02 | 20 | -0.0214 | -0.0343\n",
      "00:53:05 03 | 01 | -0.0100 | -0.0151\n",
      "00:54:21 03 | 02 | -0.0005 | -0.0002\n",
      "00:55:39 03 | 03 |  0.0236 |  0.0416\n",
      "00:56:56 03 | 04 |  0.0195 |  0.0207\n",
      "00:58:12 03 | 05 |  0.0076 | -0.0045\n",
      "00:59:28 03 | 06 |  0.0211 |  0.0408\n",
      "01:00:45 03 | 07 |  0.0346 |  0.0473\n",
      "01:02:01 03 | 08 |  0.0163 |  0.0227\n",
      "01:03:19 03 | 09 |  0.0135 |  0.0102\n",
      "01:04:36 03 | 10 | -0.0092 | -0.0135\n",
      "01:05:53 03 | 11 |  0.0121 |  0.0147\n",
      "01:07:09 03 | 12 |  0.0028 | -0.0190\n",
      "01:08:26 03 | 13 |  0.0026 |  0.0057\n",
      "01:09:42 03 | 14 | -0.0128 | -0.0032\n",
      "01:10:59 03 | 15 | -0.0019 | -0.0059\n",
      "01:12:15 03 | 16 | -0.0165 | -0.0322\n",
      "01:13:31 03 | 17 |  0.0221 |  0.0231\n",
      "01:14:48 03 | 18 | -0.0059 | -0.0070\n",
      "01:16:04 03 | 19 | -0.0068 | -0.0105\n",
      "01:17:20 03 | 20 | -0.0147 | -0.0293\n",
      "01:18:38 04 | 01 | -0.0161 | -0.0115\n",
      "01:19:56 04 | 02 | -0.0441 | -0.0323\n",
      "01:21:13 04 | 03 |  0.0063 |  0.0344\n",
      "01:22:31 04 | 04 | -0.0226 | -0.0219\n",
      "01:23:49 04 | 05 | -0.0006 | -0.0058\n",
      "01:25:06 04 | 06 |  0.0252 |  0.0064\n",
      "01:26:23 04 | 07 |  0.0069 | -0.0074\n",
      "01:27:40 04 | 08 | -0.0331 | -0.0319\n",
      "01:29:02 04 | 09 | -0.0116 | -0.0074\n",
      "01:30:31 04 | 10 | -0.0182 | -0.0400\n",
      "01:32:04 04 | 11 | -0.0194 | -0.0202\n",
      "01:33:37 04 | 12 | -0.0219 | -0.0270\n",
      "01:35:09 04 | 13 |  0.0189 | -0.0101\n",
      "01:36:42 04 | 14 |  0.0266 |  0.0033\n",
      "01:38:08 04 | 15 |  0.0015 | -0.0080\n",
      "01:39:34 04 | 16 | -0.0119 | -0.0052\n",
      "01:41:02 04 | 17 |  0.0291 |  0.0082\n",
      "01:42:30 04 | 18 | -0.0111 | -0.0028\n",
      "01:43:58 04 | 19 | -0.0036 | -0.0038\n",
      "01:45:28 04 | 20 |  0.0051 |  0.0058\n",
      "01:46:58 05 | 01 |  0.0042 | -0.0015\n",
      "01:48:17 05 | 02 | -0.0055 | -0.0069\n",
      "01:49:22 05 | 03 |  0.0175 |  0.0289\n",
      "01:50:26 05 | 04 |  0.0329 |  0.0444\n",
      "01:51:29 05 | 05 | -0.0047 | -0.0021\n",
      "01:52:32 05 | 06 |  0.0197 |  0.0144\n",
      "01:53:35 05 | 07 | -0.0059 | -0.0104\n",
      "01:54:36 05 | 08 |  0.0035 |  0.0344\n",
      "01:55:39 05 | 09 | -0.0064 | -0.0105\n",
      "01:56:44 05 | 10 | -0.0007 |  0.0018\n",
      "01:57:47 05 | 11 |  0.0000 |  0.0167\n",
      "01:58:49 05 | 12 | -0.0097 | -0.0150\n",
      "01:59:50 05 | 13 | -0.0086 |  0.0034\n",
      "02:00:45 05 | 14 |  0.0144 |  0.0176\n",
      "02:01:40 05 | 15 |  0.0120 |  0.0089\n",
      "02:02:34 05 | 16 | -0.0046 |  0.0064\n",
      "02:03:29 05 | 17 | -0.0047 | -0.0115\n",
      "02:04:23 05 | 18 |  0.0025 |  0.0013\n",
      "02:05:17 05 | 19 |  0.0055 | -0.0049\n",
      "02:06:11 05 | 20 | -0.0053 | -0.0062\n",
      "02:07:07 06 | 01 | -0.0293 | -0.0206\n",
      "02:08:00 06 | 02 |  0.0165 |  0.0208\n",
      "02:08:54 06 | 03 |  0.0092 |  0.0100\n",
      "02:09:47 06 | 04 |  0.0119 | -0.0046\n",
      "02:10:40 06 | 05 |  0.0241 |  0.0383\n",
      "02:11:33 06 | 06 |  0.0168 | -0.0027\n",
      "02:12:27 06 | 07 |  0.0152 |  0.0361\n",
      "02:13:23 06 | 08 |  0.0319 |  0.0437\n",
      "02:14:18 06 | 09 |  0.0087 |  0.0027\n",
      "02:15:10 06 | 10 |  0.0275 |  0.0206\n",
      "02:16:03 06 | 11 |  0.0133 |  0.0015\n",
      "02:16:55 06 | 12 |  0.0381 |  0.0327\n",
      "02:17:47 06 | 13 |  0.0418 |  0.0391\n",
      "02:18:38 06 | 14 |  0.0351 |  0.0469\n",
      "02:19:28 06 | 15 |  0.0363 |  0.0359\n",
      "02:20:19 06 | 16 |  0.0261 |  0.0287\n",
      "02:21:15 06 | 17 |  0.0352 |  0.0326\n",
      "02:22:09 06 | 18 |  0.0157 |  0.0044\n",
      "02:23:04 06 | 19 |  0.0119 |  0.0235\n",
      "02:23:58 06 | 20 |  0.0360 |  0.0321\n",
      "02:24:55 07 | 01 |  0.0344 |  0.0356\n",
      "02:25:48 07 | 02 |  0.0127 |  0.0388\n",
      "02:26:43 07 | 03 |  0.0199 |  0.0489\n",
      "02:27:40 07 | 04 | -0.0087 | -0.0172\n",
      "02:28:36 07 | 05 |  0.0122 |  0.0435\n",
      "02:29:35 07 | 06 |  0.0304 |  0.0531\n",
      "02:30:34 07 | 07 |  0.0191 |  0.0133\n",
      "02:31:30 07 | 08 |  0.0299 |  0.0293\n",
      "02:32:26 07 | 09 |  0.0292 |  0.0634\n",
      "02:33:23 07 | 10 |  0.0369 |  0.0718\n",
      "02:34:22 07 | 11 | -0.0037 |  0.0215\n",
      "02:35:16 07 | 12 |  0.0300 |  0.0252\n",
      "02:36:15 07 | 13 | -0.0150 | -0.0079\n",
      "02:37:14 07 | 14 |  0.0193 |  0.0327\n",
      "02:38:11 07 | 15 |  0.0062 |  0.0479\n",
      "02:39:08 07 | 16 |  0.0039 |  0.0125\n",
      "02:40:02 07 | 17 | -0.0024 | -0.0063\n",
      "02:40:60 07 | 18 | -0.0172 | -0.0025\n",
      "02:41:57 07 | 19 |  0.0025 | -0.0130\n",
      "02:42:55 07 | 20 | -0.0140 |  0.0032\n",
      "02:43:54 08 | 01 |  0.0016 |  0.0143\n",
      "02:44:50 08 | 02 | -0.0012 |  0.0220\n",
      "02:45:50 08 | 03 |  0.0021 | -0.0003\n",
      "02:46:50 08 | 04 |  0.0103 |  0.0165\n",
      "02:47:48 08 | 05 | -0.0133 | -0.0074\n",
      "02:48:48 08 | 06 |  0.0125 | -0.0011\n",
      "02:49:48 08 | 07 |  0.0219 |  0.0247\n",
      "02:50:48 08 | 08 |  0.0037 |  0.0028\n",
      "02:51:48 08 | 09 |  0.0146 |  0.0178\n",
      "02:52:48 08 | 10 |  0.0341 |  0.0345\n",
      "02:53:46 08 | 11 |  0.0071 | -0.0007\n",
      "02:54:45 08 | 12 |  0.0022 |  0.0084\n",
      "02:55:41 08 | 13 | -0.0055 |  0.0196\n",
      "02:56:33 08 | 14 |  0.0027 |  0.0169\n",
      "02:57:25 08 | 15 | -0.0043 | -0.0126\n",
      "02:58:16 08 | 16 |  0.0139 |  0.0312\n",
      "02:59:07 08 | 17 |  0.0107 | -0.0040\n",
      "02:59:58 08 | 18 |  0.0077 |  0.0222\n",
      "03:00:48 08 | 19 |  0.0097 |  0.0338\n",
      "03:01:40 08 | 20 | -0.0050 |  0.0094\n",
      "03:02:36 09 | 01 | -0.0104 | -0.0127\n",
      "03:03:27 09 | 02 |  0.0159 |  0.0045\n",
      "03:04:19 09 | 03 |  0.0035 |  0.0114\n",
      "03:05:09 09 | 04 |  0.0151 |  0.0113\n",
      "03:05:60 09 | 05 |  0.0090 |  0.0064\n",
      "03:06:49 09 | 06 | -0.0132 | -0.0298\n",
      "03:07:40 09 | 07 | -0.0101 | -0.0166\n",
      "03:08:30 09 | 08 | -0.0007 | -0.0045\n",
      "03:09:20 09 | 09 |  0.0114 |  0.0091\n",
      "03:10:10 09 | 10 | -0.0019 | -0.0110\n",
      "03:11:00 09 | 11 |  0.0090 |  0.0151\n",
      "03:11:51 09 | 12 |  0.0081 |  0.0056\n",
      "03:12:41 09 | 13 | -0.0015 | -0.0069\n",
      "03:13:32 09 | 14 |  0.0046 |  0.0021\n",
      "03:14:22 09 | 15 | -0.0048 |  0.0037\n",
      "03:15:12 09 | 16 | -0.0113 | -0.0168\n"
     ]
    }
   ],
   "source": [
    "ic = []\n",
    "scaler = StandardScaler()\n",
    "for params in param_grid:\n",
    "    dense_layers, activation, dropout = params\n",
    "    for batch_size in [64, 256]:\n",
    "        print(dense_layers, activation, dropout, batch_size)\n",
    "        checkpoint_dir = checkpoint_path / str(dense_layers) / activation / str(dropout) / str(batch_size)\n",
    "        if not checkpoint_dir.exists():\n",
    "            checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "        start = time()\n",
    "        for fold, (train_idx, test_idx) in enumerate(cv.split(X_cv)):\n",
    "            # get train & validation data\n",
    "            x_train, y_train, x_val, y_val = get_train_valid_data(X_cv, y_cv, train_idx, test_idx)\n",
    "            \n",
    "            # scale features\n",
    "            x_train = scaler.fit_transform(x_train)\n",
    "            x_val = scaler.transform(x_val)\n",
    "            \n",
    "            # set up dataframes to log results\n",
    "            preds = y_val.to_frame('actual')\n",
    "            r = pd.DataFrame(index=y_val.groupby(level='date').size().index)\n",
    "            \n",
    "            # create model based on validation parameters\n",
    "            model = make_model(dense_layers, activation, dropout)\n",
    "            \n",
    "            # cross-validate for 20 epochs\n",
    "            for epoch in range(20):            \n",
    "                model.fit(x_train,\n",
    "                          y_train,\n",
    "                          batch_size=batch_size,\n",
    "                          epochs=1,\n",
    "                          verbose=0,\n",
    "                          shuffle=True,\n",
    "                          validation_data=(x_val, y_val))\n",
    "                model.save_weights((checkpoint_dir / f'ckpt_{fold}_{epoch}').as_posix())\n",
    "                preds[epoch] = model.predict(x_val).squeeze()\n",
    "                r[epoch] = preds.groupby(level='date').apply(lambda x: spearmanr(x.actual, x[epoch])[0]).to_frame(epoch)\n",
    "                print(format_time(time()-start), f'{fold + 1:02d} | {epoch + 1:02d} | {r[epoch].mean():7.4f} | {r[epoch].median():7.4f}')\n",
    "            ic.append(r.assign(dense_layers=str(dense_layers), \n",
    "                               activation=activation, \n",
    "                               dropout=dropout,\n",
    "                               batch_size=batch_size,\n",
    "                               fold=fold))       \n",
    "\n",
    "        t = time()-start\n",
    "        pd.concat(ic).to_hdf(results_path / 'scores.h5', 'ic_by_day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate predictive performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.399489Z",
     "start_time": "2021-02-23T05:45:38.349Z"
    }
   },
   "outputs": [],
   "source": [
    "params = ['dense_layers', 'dropout', 'batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.400398Z",
     "start_time": "2021-02-23T05:45:38.351Z"
    }
   },
   "outputs": [],
   "source": [
    "ic = pd.read_hdf(results_path / 'scores.h5', 'ic_by_day').drop('activation', axis=1)\n",
    "ic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.401296Z",
     "start_time": "2021-02-23T05:45:38.353Z"
    }
   },
   "outputs": [],
   "source": [
    "ic.groupby(params).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.402062Z",
     "start_time": "2021-02-23T05:45:38.355Z"
    }
   },
   "outputs": [],
   "source": [
    "ic_long = pd.melt(ic, id_vars=params + ['fold'], var_name='epoch', value_name='ic')\n",
    "ic_long.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.402928Z",
     "start_time": "2021-02-23T05:45:38.357Z"
    }
   },
   "outputs": [],
   "source": [
    "ic_long = ic_long.groupby(params+ ['epoch', 'fold']).ic.mean().to_frame('ic').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.403975Z",
     "start_time": "2021-02-23T05:45:38.360Z"
    }
   },
   "outputs": [],
   "source": [
    "g = sns.relplot(x='epoch', y='ic', col='dense_layers', row='dropout', \n",
    "                data=ic_long[ic_long.dropout>0], kind='line')\n",
    "g.map(plt.axhline, y=0, ls='--', c='k', lw=1)\n",
    "g.savefig(results_path / 'ic_lineplot', dpi=300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.404731Z",
     "start_time": "2021-02-23T05:45:38.362Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_ols(ic):\n",
    "    ic.dense_layers = ic.dense_layers.str.replace(', ', '-').str.replace('(', '').str.replace(')', '')\n",
    "    data = pd.melt(ic, id_vars=params, var_name='epoch', value_name='ic')\n",
    "    data.epoch = data.epoch.astype(int).astype(str).apply(lambda x: f'{int(x):02.0f}')\n",
    "    model_data = pd.get_dummies(data.sort_values(params + ['epoch']), columns=['epoch'] + params, drop_first=True).sort_index(1)\n",
    "    model_data.columns = [s.split('_')[-1] for s in model_data.columns]\n",
    "    model = sm.OLS(endog=model_data.ic, exog=sm.add_constant(model_data.drop('ic', axis=1)))\n",
    "    return model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.405558Z",
     "start_time": "2021-02-23T05:45:38.364Z"
    }
   },
   "outputs": [],
   "source": [
    "model = run_ols(ic.drop('fold', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.406263Z",
     "start_time": "2021-02-23T05:45:38.366Z"
    }
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.407080Z",
     "start_time": "2021-02-23T05:45:38.367Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "\n",
    "ci = model.conf_int()\n",
    "errors = ci[1].sub(ci[0]).div(2)\n",
    "\n",
    "coefs = (model.params.to_frame('coef').assign(error=errors)\n",
    "         .reset_index().rename(columns={'index': 'variable'}))\n",
    "coefs = coefs[~coefs['variable'].str.startswith('date') & (coefs.variable != 'const')]\n",
    "\n",
    "coefs.plot(x='variable', y='coef', kind='bar',\n",
    "           ax=ax, color='none', capsize=3,\n",
    "           yerr='error', legend=False, rot=0, title='Impact of Architecture and Training Parameters on Out-of-Sample Performance')\n",
    "ax.set_ylabel('IC')\n",
    "ax.set_xlabel('')\n",
    "ax.scatter(x=pd.np.arange(len(coefs)), marker='_', s=120, y=coefs['coef'], color='black')\n",
    "ax.axhline(y=0, linestyle='--', color='black', linewidth=1)\n",
    "ax.xaxis.set_ticks_position('none')\n",
    "\n",
    "ax.annotate('Batch Size', xy=(.02, -0.1), xytext=(.02, -0.2),\n",
    "            xycoords='axes fraction',\n",
    "            textcoords='axes fraction',\n",
    "            fontsize=11, ha='center', va='bottom',\n",
    "            bbox=dict(boxstyle='square', fc='white', ec='black'),\n",
    "            arrowprops=dict(arrowstyle='-[, widthB=1.3, lengthB=0.8', lw=1.0, color='black'))\n",
    "\n",
    "ax.annotate('Layers', xy=(.1, -0.1), xytext=(.1, -0.2),\n",
    "            xycoords='axes fraction',\n",
    "            textcoords='axes fraction',\n",
    "            fontsize=11, ha='center', va='bottom',\n",
    "            bbox=dict(boxstyle='square', fc='white', ec='black'),\n",
    "            arrowprops=dict(arrowstyle='-[, widthB=4.8, lengthB=0.8', lw=1.0, color='black'))\n",
    "\n",
    "ax.annotate('Dropout', xy=(.2, -0.1), xytext=(.2, -0.2),\n",
    "            xycoords='axes fraction',\n",
    "            textcoords='axes fraction',\n",
    "            fontsize=11, ha='center', va='bottom',\n",
    "            bbox=dict(boxstyle='square', fc='white', ec='black'),\n",
    "            arrowprops=dict(arrowstyle='-[, widthB=2.8, lengthB=0.8', lw=1.0, color='black'))\n",
    "\n",
    "ax.annotate('Epochs', xy=(.62, -0.1), xytext=(.62, -0.2),\n",
    "            xycoords='axes fraction',\n",
    "            textcoords='axes fraction',\n",
    "            fontsize=11, ha='center', va='bottom',\n",
    "            bbox=dict(boxstyle='square', fc='white', ec='black'),\n",
    "            arrowprops=dict(arrowstyle='-[, widthB=30.5, lengthB=1.0', lw=1.0, color='black'))\n",
    "\n",
    "sns.despine()\n",
    "fig.tight_layout()\n",
    "fig.savefig(results_path / 'ols_coef', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.407955Z",
     "start_time": "2021-02-23T05:45:38.370Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_best_params(n=5):\n",
    "    \"\"\"Get the best parameters across all folds by daily median IC\"\"\"\n",
    "    params = ['dense_layers', 'activation', 'dropout', 'batch_size']\n",
    "    ic = pd.read_hdf(results_path / 'scores.h5', 'ic_by_day').drop('fold', axis=1)\n",
    "    dates = sorted(ic.index.unique())\n",
    "    train_period = 24 * 21\n",
    "    train_dates = dates[:train_period]\n",
    "    ic = ic.loc[train_dates]\n",
    "    return (ic.groupby(params)\n",
    "            .median()\n",
    "            .stack()\n",
    "            .to_frame('ic')\n",
    "            .reset_index()\n",
    "            .rename(columns={'level_4': 'epoch'})\n",
    "            .nlargest(n=n, columns='ic')\n",
    "            .drop('ic', axis=1)\n",
    "            .to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.408720Z",
     "start_time": "2021-02-23T05:45:38.373Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_predictions(dense_layers, activation, dropout, batch_size, epoch):\n",
    "    data = pd.read_hdf('../12_gradient_boosting_machines/data.h5', 'model_data').dropna().sort_index()\n",
    "    outcomes = data.filter(like='fwd').columns.tolist()\n",
    "    X_cv = data.loc[idx[:, :'2017'], :].drop(outcomes, axis=1)\n",
    "    input_dim = X_cv.shape[1]\n",
    "    y_cv = data.loc[idx[:, :'2017'], 'r01_fwd']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    predictions = []\n",
    "    \n",
    "    do = '0' if str(dropout) == '0.0' else str(dropout)\n",
    "    checkpoint_dir = checkpoint_path / str(dense_layers) / activation / str(do) / str(batch_size)\n",
    "        \n",
    "    for fold, (train_idx, test_idx) in enumerate(cv.split(X_cv)):\n",
    "        x_train, y_train, x_val, y_val = get_train_valid_data(X_cv, y_cv, train_idx, test_idx)\n",
    "        x_val = scaler.fit(x_train).transform(x_val)\n",
    "        model = make_model(make_tuple(dense_layers), activation, dropout)\n",
    "        status = model.load_weights((checkpoint_dir / f'ckpt_{fold}_{epoch}').as_posix())\n",
    "        status.expect_partial()\n",
    "        predictions.append(pd.Series(model.predict(x_val).squeeze(), index=y_val.index))\n",
    "    return pd.concat(predictions)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.409529Z",
     "start_time": "2021-02-23T05:45:38.375Z"
    }
   },
   "outputs": [],
   "source": [
    "best_params = get_best_params()\n",
    "predictions = []\n",
    "for i, params in enumerate(best_params):\n",
    "    predictions.append(generate_predictions(**params).to_frame(i))\n",
    "\n",
    "predictions = pd.concat(predictions, axis=1)\n",
    "print(predictions.info())\n",
    "predictions.to_hdf(results_path / 'test_preds.h5', 'predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to further improve the results\n",
    "\n",
    "The relatively simple architecture yields some promising results. To further improve performance, you can\n",
    "- First and foremost, add new features and more data to the model\n",
    "- Expand the set of architectures to explore, including more or wider layers\n",
    "- Inspect the training progress and train for more epochs if the validation error continued to improve at 50 epochs\n",
    "\n",
    "Finally, you can use more sophisticated architectures, including Recurrent Neural Networks (RNN) and Convolutional Neural Networks that are well suited to sequential data, whereas vanilla feedforward NNs are not designed to capture the ordered nature of the features.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_env]",
   "language": "python",
   "name": "conda-env-tensorflow_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "282.222px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
