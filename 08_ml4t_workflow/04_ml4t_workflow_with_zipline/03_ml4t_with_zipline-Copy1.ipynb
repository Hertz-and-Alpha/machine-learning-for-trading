{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML4T Workflow with zipline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also integrate the model training into our backtest. The goal is to replicate the daily return predictions we used in [backtesting_with_zipline](02_backtesting_with_zipline.ipynb) and generated in [Chapter 7](../../07_linear_models). \n",
    "\n",
    "We will, however, use a few additional Pipeline factors to illustrate their usage. The principal new element is a CustomFactor that receives features and returns as inputs to train a model and produce predictions. We follow the workflow displayed in the following figure:\n",
    "\n",
    "![ML4T with Zipline](../../assets/zip_pipe_model_flow.png \"ML4T Workflow with Zipline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:22:15.862511Z",
     "start_time": "2021-04-15T20:22:15.859518Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:22:17.040743Z",
     "start_time": "2021-04-15T20:22:15.864782Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from logbook import Logger, StderrHandler, INFO\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from zipline.pipeline import Pipeline, CustomFactor\n",
    "from zipline.pipeline.data import USEquityPricing\n",
    "from zipline.pipeline.factors import AverageDollarVolume, EWMA, Returns\n",
    "from zipline.pipeline.factors.technical import RSI, MACDSignal, TrueRange\n",
    "from zipline import run_algorithm\n",
    "from zipline.api import (attach_pipeline, pipeline_output,\n",
    "                         date_rules, time_rules,\n",
    "                         schedule_function, commission, slippage,\n",
    "                         set_slippage, set_commission,\n",
    "                         record,\n",
    "                         order_target, order_target_percent)\n",
    "\n",
    "import pyfolio as pf\n",
    "from pyfolio.plotting import plot_rolling_returns, plot_rolling_sharpe\n",
    "from pyfolio.timeseries import forecast_cone_bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:22:17.043812Z",
     "start_time": "2021-04-15T20:22:17.041738Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:22:17.057600Z",
     "start_time": "2021-04-15T20:22:17.044838Z"
    }
   },
   "outputs": [],
   "source": [
    "log_handler = StderrHandler(\n",
    "        format_string='[{record.time:%Y-%m-%d %H:%M:%S.%f}]: ' +\n",
    "                      '{record.level_name}: {record.func_name}: {record.message}',\n",
    "        level=INFO\n",
    ")\n",
    "log_handler.push_application()\n",
    "log = Logger('Algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algo Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:22:17.066093Z",
     "start_time": "2021-04-15T20:22:17.058614Z"
    }
   },
   "outputs": [],
   "source": [
    "# Target long/short positions\n",
    "N_LONGS = 25\n",
    "N_SHORTS = 25\n",
    "MIN_POSITIONS = 15\n",
    "\n",
    "UNIVERSE = 250\n",
    "\n",
    "# Length of the training period (memory-intensive due to pre-processing)\n",
    "TRAINING_PERIOD = 252 * 2\n",
    "\n",
    "# train to predict N day forward returns\n",
    "N_FORWARD_DAYS = 1\n",
    "\n",
    "# How often to trade; align with prediction horizon\n",
    "# for weekly, set to date_rules.week_start(days_offset=1)\n",
    "TRADE_FREQ = date_rules.every_day()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:22:17.082223Z",
     "start_time": "2021-04-15T20:22:17.067011Z"
    }
   },
   "outputs": [],
   "source": [
    "start = pd.Timestamp('2015-01-01', tz='UTC')\n",
    "end = pd.Timestamp('2017-12-31', tz='UTC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a Pipeline Factor, we need one or more input variables, a window_length that indicates the number of most recent data points for each input and security, and the computation we want to conduct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use ten custom and built-in factors as features for our model to capture risk factors like momentum and volatility. Next, weâ€™ll come up with a CustomFactor that trains our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:22:17.102088Z",
     "start_time": "2021-04-15T20:22:17.083110Z"
    }
   },
   "outputs": [],
   "source": [
    "def Price_Momentum_3M():\n",
    "    return Returns(window_length=63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:22:17.112735Z",
     "start_time": "2021-04-15T20:22:17.102886Z"
    }
   },
   "outputs": [],
   "source": [
    "def Returns_39W():\n",
    "    return Returns(window_length=215)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:22:17.120830Z",
     "start_time": "2021-04-15T20:22:17.114050Z"
    }
   },
   "outputs": [],
   "source": [
    "class Vol_3M(CustomFactor):\n",
    "    # 3 months volatility\n",
    "    inputs = [Returns(window_length=2)]\n",
    "    window_length = 63\n",
    "\n",
    "    def compute(self, today, assets, out, rets):\n",
    "        out[:] = np.nanstd(rets, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Reversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:22:17.129206Z",
     "start_time": "2021-04-15T20:22:17.121920Z"
    }
   },
   "outputs": [],
   "source": [
    "class Mean_Reversion_1M(CustomFactor):\n",
    "    # standardized difference between latest monthly return\n",
    "    # and their annual average \n",
    "    inputs = [Returns(window_length=21)]\n",
    "    window_length = 252\n",
    "\n",
    "    def compute(self, today, assets, out, monthly_rets):\n",
    "        out[:] = (monthly_rets[-1] - np.nanmean(monthly_rets, axis=0)) / \\\n",
    "                 np.nanstd(monthly_rets, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Money Flow Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:22:17.137287Z",
     "start_time": "2021-04-15T20:22:17.130109Z"
    }
   },
   "outputs": [],
   "source": [
    "class Moneyflow_Volume_5d(CustomFactor):\n",
    "    inputs = [USEquityPricing.close, USEquityPricing.volume]\n",
    "    window_length = 5\n",
    "\n",
    "    def compute(self, today, assets, out, close, volume):\n",
    "\n",
    "        mfvs = []\n",
    "\n",
    "        for col_c, col_v in zip(close.T, volume.T):\n",
    "\n",
    "            # denominator\n",
    "            denominator = np.dot(col_c, col_v)\n",
    "\n",
    "            # numerator\n",
    "            numerator = 0.\n",
    "            for n, price in enumerate(col_c.tolist()):\n",
    "                if price > col_c[n - 1]:\n",
    "                    numerator += price * col_v[n]\n",
    "                else:\n",
    "                    numerator -= price * col_v[n]\n",
    "\n",
    "            mfvs.append(numerator / denominator)\n",
    "        out[:] = mfvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price Trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear price trend that we estimate using linear regression (see [Chapter 7](../../07_linear_models) works as follows: we use the 252 latest close prices to compute the regression coefficient on a linear time trend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:22:17.145613Z",
     "start_time": "2021-04-15T20:22:17.138170Z"
    }
   },
   "outputs": [],
   "source": [
    "class Trendline(CustomFactor):\n",
    "    # linear 12 month price trend regression\n",
    "    inputs = [USEquityPricing.close]\n",
    "    window_length = 252\n",
    "\n",
    "    def compute(self, today, assets, out, close):\n",
    "        X = np.arange(self.window_length).reshape(-1, 1).astype(float)\n",
    "        X -= X.mean()\n",
    "        Y = close - np.nanmean(close, axis=0)\n",
    "        out[:] = (X.T @ Y / np.var(X)) / self.window_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price Oscillator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:22:17.153993Z",
     "start_time": "2021-04-15T20:22:17.146573Z"
    }
   },
   "outputs": [],
   "source": [
    "class Price_Oscillator(CustomFactor):\n",
    "    inputs = [USEquityPricing.close]\n",
    "    window_length = 252\n",
    "\n",
    "    def compute(self, today, assets, out, close):\n",
    "        four_week_period = close[-20:]\n",
    "        out[:] = (np.nanmean(four_week_period, axis=0) /\n",
    "                  np.nanmean(close, axis=0)) - 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:22:17.165460Z",
     "start_time": "2021-04-15T20:22:17.154930Z"
    }
   },
   "outputs": [],
   "source": [
    "vol_3M = Vol_3M()\n",
    "mean_reversion_1M = Mean_Reversion_1M()\n",
    "macd_signal_10d = MACDSignal()\n",
    "moneyflow_volume_5d = Moneyflow_Volume_5d()\n",
    "trendline = Trendline()\n",
    "price_oscillator = Price_Oscillator()\n",
    "price_momentum_3M = Price_Momentum_3M()\n",
    "returns_39W = Returns_39W()\n",
    "true_range = TrueRange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:22:17.173391Z",
     "start_time": "2021-04-15T20:22:17.166466Z"
    }
   },
   "outputs": [],
   "source": [
    "features = {\n",
    "    'Vol 3M'             : vol_3M,\n",
    "    'Mean Reversion 1M'  : mean_reversion_1M,\n",
    "    'MACD Signal 10d'    : macd_signal_10d,\n",
    "    'Moneyflow Volume 5D': moneyflow_volume_5d,\n",
    "    'Trendline'          : trendline,\n",
    "    'Price Oscillator'   : price_oscillator,\n",
    "    'Price Momentum 3M'  : price_momentum_3M,\n",
    "    '39 Week Returns'    : returns_39W,\n",
    "    'True Range'         : true_range\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML CustomFactor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `CustomFactor` called LinearModel will have the `StandardScaler` and a stochastic gradient descent (SGD) implementation of ridge regression as instance attributes, and we will train the model on three days a week.\n",
    "\n",
    "- The `compute` method generates predictions (addressing potential missing values), but first checks if the model should be trained.\n",
    "- The `_train_model` method is the centerpiece of the puzzle. It shifts the returns and aligns the resulting forward returns with the Factor features, removing missing values in the process. It scales the remaining data points and trains the linear SGDRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:22:17.181717Z",
     "start_time": "2021-04-15T20:22:17.174201Z"
    }
   },
   "outputs": [],
   "source": [
    "class LinearModel(CustomFactor):\n",
    "    \"\"\"Obtain model predictions\"\"\"\n",
    "    train_on_weekday = [0, 2, 4]\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(self, *args, **kwargs)\n",
    "\n",
    "        self._scaler = StandardScaler()\n",
    "        self._model = SGDRegressor(penalty='L2')\n",
    "        self._trained = False\n",
    "\n",
    "    def _train_model(self, today, returns, inputs):\n",
    "\n",
    "        scaler = self._scaler\n",
    "        model = self._model\n",
    "\n",
    "        shift_by = N_FORWARD_DAYS + 1\n",
    "        outcome = returns[shift_by:].flatten()\n",
    "        features = np.dstack(inputs)[:-shift_by]\n",
    "        n_days, n_stocks, n_features = features.shape\n",
    "        features = features.reshape(-1, n_features)\n",
    "        features = features[~np.isnan(outcome)]\n",
    "        outcome = outcome[~np.isnan(outcome)]\n",
    "        outcome = outcome[np.all(~np.isnan(features), axis=1)]\n",
    "        features = features[np.all(~np.isnan(features), axis=1)]\n",
    "        features = scaler.fit_transform(features)\n",
    "\n",
    "        start = time()\n",
    "        model.fit(X=features, y=outcome)\n",
    "#         log.info('{} | {:.2f}s'.format(today.date(), time() - start))\n",
    "        self._trained = True\n",
    "\n",
    "    def _maybe_train_model(self, today, returns, inputs):\n",
    "        if (today.weekday() in self.train_on_weekday) or not self._trained:\n",
    "            self._train_model(today, returns, inputs)\n",
    "\n",
    "    def compute(self, today, assets, out, returns, *inputs):\n",
    "        self._maybe_train_model(today, returns, inputs)\n",
    "\n",
    "        # Predict most recent feature values\n",
    "        X = np.dstack(inputs)[-1]\n",
    "        missing = np.any(np.isnan(X), axis=1)\n",
    "        X[missing, :] = 0\n",
    "        X = self._scaler.transform(X)\n",
    "        preds = self._model.predict(X)\n",
    "        out[:] = np.where(missing, np.nan, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `make_ml_pipeline()` function preprocesses and combines the outcome, feature, and model parts into a Pipeline with a column for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:22:17.197683Z",
     "start_time": "2021-04-15T20:22:17.182615Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_ml_pipeline(universe, window_length=21, n_forward_days=5):\n",
    "    pipeline_columns = OrderedDict()\n",
    "\n",
    "    # ensure that returns is the first input\n",
    "    pipeline_columns['Returns'] = Returns(inputs=[USEquityPricing.open],\n",
    "                                          mask=universe,\n",
    "                                          window_length=n_forward_days + 1)\n",
    "\n",
    "    # convert factors to ranks; append to pipeline\n",
    "    pipeline_columns.update({k: v.rank(mask=universe)\n",
    "                             for k, v in features.items()})\n",
    "\n",
    "    # Create ML pipeline factor.\n",
    "    # window_length = length of the training period\n",
    "    pipeline_columns['predictions'] = LinearModel(inputs=pipeline_columns.values(),\n",
    "                                         window_length=window_length + n_forward_days,\n",
    "                                         mask=universe)\n",
    "\n",
    "    return Pipeline(screen=universe, columns=pipeline_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:22:17.213250Z",
     "start_time": "2021-04-15T20:22:17.198577Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_universe():\n",
    "    # Set screen\n",
    "    dollar_volume = AverageDollarVolume(window_length=90)\n",
    "    return dollar_volume.top(UNIVERSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:22:17.221964Z",
     "start_time": "2021-04-15T20:22:17.214241Z"
    }
   },
   "outputs": [],
   "source": [
    "universe = make_universe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:22:17.229668Z",
     "start_time": "2021-04-15T20:22:17.222925Z"
    }
   },
   "outputs": [],
   "source": [
    "def initialize(context):\n",
    "    \"\"\"\n",
    "    Called once at the start of the algorithm.\n",
    "    \"\"\"\n",
    "    \n",
    "    set_slippage(slippage.FixedSlippage(spread=0.00))\n",
    "    set_commission(commission.PerShare(cost=0, min_trade_cost=0))\n",
    "\n",
    "    schedule_function(rebalance, TRADE_FREQ,\n",
    "                      date_rules.every_day(),\n",
    "                      time_rules.market_open(hours=1, minutes=30),\n",
    "    )\n",
    "\n",
    "    schedule_function(record_vars, date_rules.every_day(),\n",
    "                      time_rules.market_close())\n",
    "\n",
    "    ml_pipeline = make_ml_pipeline(universe,\n",
    "                                   n_forward_days=N_FORWARD_DAYS,\n",
    "                                   window_length=TRAINING_PERIOD)\n",
    "\n",
    "    # Create our dynamic stock selector.\n",
    "    attach_pipeline(ml_pipeline, 'ml_model')\n",
    "\n",
    "    context.past_predictions = {}\n",
    "    context.ic = 0\n",
    "    context.rmse = 0\n",
    "    context.mae = 0\n",
    "    context.returns_spread_bps = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Predictive Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `evaluate_predictions()` function does exactly this: it tracks the past predictions of our model and evaluates them once returns for the relevant time horizon materialize (in our example the next day):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:22:17.237889Z",
     "start_time": "2021-04-15T20:22:17.230840Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_predictions(output, context):\n",
    "    # Look at past predictions to evaluate model performance\n",
    "    # A day has passed, shift days and drop old ones\n",
    "    context.past_predictions = {\n",
    "        k - 1: v for k, v in context.past_predictions.items() if k > 0\n",
    "    }\n",
    "\n",
    "    if 0 in context.past_predictions:\n",
    "        \n",
    "        # Use today's n-day returns to evaluate predictions\n",
    "        returns, predictions = (output['Returns'].dropna()\n",
    "                                .align(context.past_predictions[0].dropna(),\n",
    "                                       join='inner'))\n",
    "        if len(returns) > 0 and len(predictions) > 0:\n",
    "            context.ic = spearmanr(returns, predictions)[0]\n",
    "            context.rmse = np.sqrt(\n",
    "                mean_squared_error(returns, predictions))\n",
    "            context.mae = mean_absolute_error(returns, predictions)\n",
    "\n",
    "            long_rets = returns[predictions > 0].mean()\n",
    "            short_rets = returns[predictions < 0].mean()\n",
    "            context.returns_spread_bps = (long_rets - short_rets) * 10000\n",
    "\n",
    "    # Store current predictions\n",
    "    context.past_predictions[N_FORWARD_DAYS] = context.predicted_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Pipeline Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain new predictions using the `before_trading_start()` function that runs every morning before market open:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:34:36.177163Z",
     "start_time": "2021-04-15T20:34:36.169038Z"
    }
   },
   "outputs": [],
   "source": [
    "def before_trading_start(context, data):\n",
    "    \"\"\"\n",
    "    Called every day before market open.\n",
    "    \"\"\"\n",
    "    output = pipeline_output('ml_model')\n",
    "    context.predicted_returns = output['predictions']\n",
    "    context.predicted_returns.index.set_names(['equity'], inplace=True)\n",
    "\n",
    "    evaluate_predictions(output, context)\n",
    "\n",
    "    # These are the securities that we are interested in trading each day.\n",
    "    context.security_list = context.predicted_returns.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:34:36.694914Z",
     "start_time": "2021-04-15T20:34:36.684375Z"
    }
   },
   "outputs": [],
   "source": [
    "def rebalance(context, data):\n",
    "    \"\"\"\n",
    "    Execute orders according to our schedule_function() timing.\n",
    "    \"\"\"\n",
    "    predictions = context.predicted_returns\n",
    "\n",
    "    # Drop stocks that can not be traded\n",
    "    predictions = predictions.loc[data.can_trade(predictions.index)]\n",
    "    longs = (predictions[predictions > 0]\n",
    "             .sort_values(ascending=False)[:N_LONGS]\n",
    "             .index\n",
    "             .tolist())\n",
    "    shorts = (predictions[predictions < 0]\n",
    "              .sort_values()[:N_SHORTS]\n",
    "              .index\n",
    "              .tolist())\n",
    "    targets = set(longs + shorts)\n",
    "    for position in context.portfolio.positions:\n",
    "        if position not in targets:\n",
    "            order_target(position, 0)\n",
    "    \n",
    "    n_longs, n_shorts = len(longs), len(shorts)\n",
    "    if n_longs > MIN_POSITIONS and n_shorts > MIN_POSITIONS:\n",
    "        for stock in longs:\n",
    "            order_target_percent(stock, target=1/n_longs)\n",
    "        for stock in shorts:\n",
    "            order_target_percent(stock, target=-1/n_shorts)\n",
    "    else:\n",
    "        for stock in targets:\n",
    "            if stock in context.portfolio.positions:\n",
    "                order_target(stock, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:34:37.034292Z",
     "start_time": "2021-04-15T20:34:37.029284Z"
    }
   },
   "outputs": [],
   "source": [
    "def record_vars(context, data):\n",
    "    \"\"\"\n",
    "    Plot variables at the end of each day.\n",
    "    \"\"\"\n",
    "    record(\n",
    "            leverage=context.account.leverage,\n",
    "            ic=context.ic,\n",
    "            rmse=context.rmse,\n",
    "            mae=context.mae,\n",
    "            returns_spread_bps=context.returns_spread_bps\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:39:50.995172Z",
     "start_time": "2021-04-15T20:34:37.821853Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 03:48:00.937384]: WARNING: _can_order_asset: Cannot place order for PCYC, as it has de-listed. Any existing positions for this asset will be liquidated on 2015-05-23 00:00:00+00:00.\n",
      "[2021-05-17 03:48:06.091820]: INFO: handle_split: after split: asset: Equity(1623 [KR]), amount: 1002, cost_basis: 38.48, last_sale_price: 76.95\n",
      "[2021-05-17 03:48:06.092820]: INFO: handle_split: returning cash: 0.0\n",
      "[2021-05-17 03:48:49.671816]: WARNING: _can_order_asset: Cannot place order for PLL, as it has de-listed. Any existing positions for this asset will be liquidated on 2015-08-29 00:00:00+00:00.\n",
      "[2021-05-17 03:49:04.168590]: INFO: handle_split: after split: asset: Equity(1992 [NKE]), amount: 614, cost_basis: 65.92, last_sale_price: 128.71\n",
      "[2021-05-17 03:49:04.169591]: INFO: handle_split: returning cash: 0.0\n",
      "[2021-05-17 03:51:06.101164]: WARNING: _can_order_asset: Cannot place order for LNKD, as it has de-listed. Any existing positions for this asset will be liquidated on 2016-12-08 00:00:00+00:00.\n",
      "[2021-05-17 03:51:50.785936]: WARNING: _can_order_asset: Cannot place order for ARIA, as it has de-listed. Any existing positions for this asset will be liquidated on 2017-02-16 00:00:00+00:00.\n"
     ]
    }
   ],
   "source": [
    "go = time()\n",
    "results = run_algorithm(start=start,\n",
    "                        end=end,\n",
    "                        initialize=initialize,\n",
    "                        before_trading_start=before_trading_start,\n",
    "                        capital_base=1e6,\n",
    "                        data_frequency='daily',\n",
    "                        benchmark_returns=None,\n",
    "                        bundle='quandl')\n",
    "\n",
    "print('{:.2f}'.format(time()-go))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze using PyFolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:39:51.405765Z",
     "start_time": "2021-04-15T20:39:50.996155Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "axes = (results[['ic', 'returns_spread_bps']]\n",
    "        .dropna()\n",
    "        .rolling(21)\n",
    "        .mean()\n",
    "        .plot(subplots=True, \n",
    "              layout=(2,1), \n",
    "              figsize=(14, 6), \n",
    "              title=['Informmation Coefficient (21-day Rolling Avg.)', 'Returns Spread (bps, 21-day Rolling Avg.)'],\n",
    "              legend=False))\n",
    "axes = axes.flatten()\n",
    "axes[0].set_ylabel('IC')\n",
    "axes[1].set_ylabel('bps')\n",
    "plt.suptitle('Model Performance', fontsize=14)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=.9);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get PyFolio Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:39:52.311609Z",
     "start_time": "2021-04-15T20:39:51.406852Z"
    }
   },
   "outputs": [],
   "source": [
    "returns, positions, transactions = pf.utils.extract_rets_pos_txn_from_zipline(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Benchmark Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:39:52.972647Z",
     "start_time": "2021-04-15T20:39:52.312971Z"
    }
   },
   "outputs": [],
   "source": [
    "benchmark = web.DataReader('SP500', 'fred', '2014', '2018').squeeze()\n",
    "benchmark = benchmark.pct_change().tz_localize('UTC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Performance Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:39:53.562338Z",
     "start_time": "2021-04-15T20:39:52.976741Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(16, 5))\n",
    "plot_rolling_returns(returns,\n",
    "                     factor_returns=benchmark,\n",
    "                     live_start_date='2017-01-01',\n",
    "                     logy=False,\n",
    "                     cone_std=2,\n",
    "                     legend_loc='best',\n",
    "                     volatility_match=False,\n",
    "                     cone_function=forecast_cone_bootstrap,\n",
    "                    ax=axes[0])\n",
    "plot_rolling_sharpe(returns, ax=axes[1])\n",
    "axes[0].set_title('Cumulative Returns - In and Out-of-Sample')\n",
    "sns.despine()\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Tearsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:40:41.027319Z",
     "start_time": "2021-04-15T20:39:59.613222Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pf.create_full_tear_sheet(returns, \n",
    "                          positions=positions, \n",
    "                          transactions=transactions,\n",
    "                          benchmark_rets=benchmark,\n",
    "                          live_start_date='2017-01-01', \n",
    "                          round_trips=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml4t]",
   "language": "python",
   "name": "conda-env-ml4t-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "512px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
