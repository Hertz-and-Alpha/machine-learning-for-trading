{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long-Short Strategy, Part 2: Trading signals with LightGBM and CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll start designing, implementing, and evaluating a trading strategy for US equities driven by daily return forecasts produced by gradient boosting models.\n",
    "\n",
    "As in the previous examples, we'll lay out a framework and build a specific example that you can adapt to run your own experiments. There are numerous aspects that you can vary, from the asset class and investment universe to more granular aspects like the features, holding period, or trading rules. See, for example, the **Alpha Factor Library** in the [Appendix](../24_alpha_factor_library) for numerous additional features.\n",
    "\n",
    "We'll keep the trading strategy simple and only use a single ML signal; a real-life application will likely use multiple signals from different sources, such as complementary ML models trained on different datasets or with different lookahead or lookback periods. It would also use sophisticated risk management, from simple stop-loss to value-at-risk analysis.\n",
    "\n",
    "**Six notebooks** cover our workflow sequence:\n",
    "\n",
    "1. [preparing_the_model_data](04_preparing_the_model_data.ipyny): we engineer a few simple features from the Quandl Wiki data \n",
    "2. `trading_signals_with_lightgbm_and_catboost`  (this noteboook): we tune hyperparameters for LightGBM and CatBoost to select a model, using 2015/16 as our validation period. \n",
    "3. [evaluate_trading_signals](06_evaluate_trading_signals.ipynb): we compare the cross-validation performance using various metrics to select the best model. \n",
    "4. [model_interpretation](07_model_interpretation.ipynb): we take a closer look at the drivers behind the best model's predictions.\n",
    "5. [making_out_of_sample_predictions](08_making_out_of_sample_predictions.ipynb): we generate predictions for our out-of-sample test period 2017.\n",
    "6. [backtesting_with_zipline](09_backtesting_with_zipline.ipynb): evaluate the historical performance of a long-short strategy based on our predictive signals using Zipline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll subset the dataset created in the preceding notebook through the end of 2016 to cross-validate several model configurations for various lookback and lookahead windows, as well as different roll-forward periods and hyperparameters. \n",
    "\n",
    "Our approach to model selection will be similar to the one we used in the previous chapter and uses the custom `MultipleTimeSeriesCV` introduced in [Chapter 7, Linear Models – From Risk Factors to Return Forecasts](../07_linear_models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:53.361121Z",
     "start_time": "2020-06-21T03:15:53.359422Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:54.473652Z",
     "start_time": "2020-06-21T03:15:53.619170Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import sys, os\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from alphalens.tears import (create_summary_tear_sheet,\n",
    "                             create_full_tear_sheet)\n",
    "\n",
    "from alphalens.utils import get_clean_factor_and_forward_returns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:54.477216Z",
     "start_time": "2020-06-21T03:15:54.474618Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from utils import MultipleTimeSeriesCV, format_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:54.489618Z",
     "start_time": "2020-06-21T03:15:54.478409Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:54.626839Z",
     "start_time": "2020-06-21T03:15:54.624975Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "YEAR = 252\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the train and validation sets, and identify labels and features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:58.610627Z",
     "start_time": "2020-06-21T03:15:56.699840Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 1745684 entries, ('A', Timestamp('2010-01-04 00:00:00')) to ('UDR', Timestamp('2016-12-30 00:00:00'))\n",
      "Data columns (total 34 columns):\n",
      " #   Column           Non-Null Count    Dtype  \n",
      "---  ------           --------------    -----  \n",
      " 0   dollar_vol       1745684 non-null  float64\n",
      " 1   dollar_vol_rank  1745684 non-null  float64\n",
      " 2   rsi              1731782 non-null  float64\n",
      " 3   bb_high          1726817 non-null  float64\n",
      " 4   bb_low           1726814 non-null  float64\n",
      " 5   NATR             1731782 non-null  float64\n",
      " 6   ATR              1731782 non-null  float64\n",
      " 7   PPO              1720859 non-null  float64\n",
      " 8   MACD             1712915 non-null  float64\n",
      " 9   sector           1745684 non-null  int32  \n",
      " 10  r01              1744691 non-null  float64\n",
      " 11  r05              1740719 non-null  float64\n",
      " 12  r10              1735754 non-null  float64\n",
      " 13  r21              1724831 non-null  float64\n",
      " 14  r42              1703978 non-null  float64\n",
      " 15  r63              1683125 non-null  float64\n",
      " 16  r01dec           1744691 non-null  float64\n",
      " 17  r05dec           1740719 non-null  float64\n",
      " 18  r10dec           1735754 non-null  float64\n",
      " 19  r21dec           1724831 non-null  float64\n",
      " 20  r42dec           1703978 non-null  float64\n",
      " 21  r63dec           1683125 non-null  float64\n",
      " 22  r01q_sector      1744691 non-null  float64\n",
      " 23  r05q_sector      1740719 non-null  float64\n",
      " 24  r10q_sector      1735754 non-null  float64\n",
      " 25  r21q_sector      1724831 non-null  float64\n",
      " 26  r42q_sector      1703978 non-null  float64\n",
      " 27  r63q_sector      1683125 non-null  float64\n",
      " 28  r01_fwd          1745684 non-null  float64\n",
      " 29  r05_fwd          1745684 non-null  float64\n",
      " 30  r21_fwd          1745669 non-null  float64\n",
      " 31  year             1745684 non-null  int64  \n",
      " 32  month            1745684 non-null  int64  \n",
      " 33  weekday          1745684 non-null  int64  \n",
      "dtypes: float64(30), int32(1), int64(3)\n",
      "memory usage: 453.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data = (pd.read_hdf('data.h5', 'model_data')\n",
    "            .sort_index()\n",
    "            .loc[idx[:, :'2016'], :]) # train & validation period\n",
    "data.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:58.627071Z",
     "start_time": "2020-06-21T03:15:58.611792Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = sorted(data.filter(like='_fwd').columns)\n",
    "features = data.columns.difference(labels).tolist() # features are columns not containing '_fwd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection: Lookback, lookahead and roll-forward periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:58.713463Z",
     "start_time": "2020-06-21T03:15:58.628189Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tickers = data.index.get_level_values('symbol').unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to predict 1, 5 or 21-day returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:58.716838Z",
     "start_time": "2020-06-21T03:15:58.714860Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lookaheads = [1, 5, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:58.726739Z",
     "start_time": "2020-06-21T03:15:58.718248Z"
    }
   },
   "outputs": [],
   "source": [
    "categoricals = ['year', 'month', 'sector', 'weekday']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select 4.5 and one years as the length of our training periods; test periods are one and three months long. Since we are using two years (2015/16) for validation, a one-month test period implies 24 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:58.735386Z",
     "start_time": "2020-06-21T03:15:58.728023Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_lengths = [int(4.5 * 252), 252]\n",
    "test_lengths = [63, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:58.743174Z",
     "start_time": "2020-06-21T03:15:58.737182Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_params = list(product(lookaheads, train_lengths, test_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:58.751241Z",
     "start_time": "2020-06-21T03:15:58.744605Z"
    }
   },
   "outputs": [],
   "source": [
    "results_path = Path('results', 'us_stocks')\n",
    "if not results_path.exists():\n",
    "    results_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We always want to know how much our (gradient boosting) is improving over a simpler baseline (if at all..)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:16:05.129548Z",
     "start_time": "2020-06-21T03:16:05.127693Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.679350Z",
     "start_time": "2020-06-21T03:16:05.270137Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [05:50<00:00, 29.21s/it]\n"
     ]
    }
   ],
   "source": [
    "lr_metrics = []\n",
    "\n",
    "# iterate over our three CV configuration parameters\n",
    "for lookahead, train_length, test_length in tqdm(test_params):\n",
    "    label = f'r{lookahead:02}_fwd'\n",
    "    df = pd.get_dummies(data.loc[:, features + [label]].dropna(), \n",
    "                        columns=categoricals, \n",
    "                        drop_first=True)\n",
    "    X, y = df.drop(label, axis=1), df[label]\n",
    "\n",
    "    n_splits = int(2 * YEAR / test_length)\n",
    "    cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                              test_period_length=test_length,\n",
    "                              lookahead=lookahead,\n",
    "                              train_period_length=train_length)\n",
    "\n",
    "    ic, preds = [], []\n",
    "    for i, (train_idx, test_idx) in enumerate(cv.split(X=X)):\n",
    "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "        lr.fit(X_train, y_train)\n",
    "        y_pred = lr.predict(X_test)\n",
    "        preds.append(y_test.to_frame('y_true').assign(y_pred=y_pred))\n",
    "        ic.append(spearmanr(y_test, y_pred)[0])\n",
    "    preds = pd.concat(preds)\n",
    "    lr_metrics.append([lookahead, \n",
    "                       train_length, \n",
    "                       test_length,\n",
    "                       np.mean(ic),\n",
    "                       spearmanr(preds.y_true, preds.y_pred)[0]\n",
    "                      ])\n",
    "\n",
    "columns = ['lookahead', 'train_length', 'test_length', 'ic_by_day', 'ic']\n",
    "lr_metrics = pd.DataFrame(lr_metrics, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Coefficient - Distribution by Lookahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.897475Z",
     "start_time": "2020-06-21T03:19:37.680445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+gAAAFgCAYAAAAo31N4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAu9ElEQVR4nO3de3RU5aH+8WeSkMswhJjI4SIXY0IQqzUEupYKqCDUIQuECJFEFnIE9dgWIlC5iICAEC4KlVTABWoPcjgSRW25xFQRlAP1BiVFBDQJh+ixGoEBYZiQ28zvD8r8SjEOSZi9dzLfz1pdZfaePe8zScw7T/bN5vP5fAIAAAAAAKYKMzsAAAAAAACgoAMAAAAAYAkUdAAAAAAALICCDgAAAACABVDQAQAAAACwAAo6AAAAAAAWEGF2AADW0b9/fy1fvlw33XSTJGnHjh16+eWXdfr0adXU1Khr166aNm2a2rdvf8m23bp104cffqj4+PgGj92iRQtFR0fL5/PJ5/MpPT1dDz/8sCIi+FUFAGgeGjPXStKHH36olStXqry8XNHR0UpISNBvfvMb9erVK+jZP/74Yz399NPasmWLpk+frq5du2rcuHFBHxcIJXzqBfCjNm/erFWrVmnVqlXq0qWLfD6fVq9erQceeEBbt25VZGTkFR/z2Wef9X9g8Xg8evzxx7Vw4ULNmjXrio8FAIDZ6jvXvvfee1q0aJGWLFmiHj16SJKKioo0adIkzZkzR3fccYcZbwPAFcQh7gB+1O9+9zs9+eST6tKliyTJZrPpkUce0YQJE1RVVfWj2zz33HPKyMjQ0KFDtWPHDknSgw8+qNdee83/nJUrVyo3Nzfg+Ha7XbNnz1Z+fr7cbrc8Ho+mTp2qkSNH6u6779a9996rI0eO6O9//7vS0tJ05swZSZLP59Pdd9+tw4cPN/ZLAABAUNV3rl2yZIlmzpzpL+eSlJqaqhkzZmjJkiU6c+aM0tLSdOzYMf/6zMxMffDBB6qqqlJubq4yMjJ0zz33aPr06XK73ZLO79WfOHGiBg0apHfffVc7duxQVlaW7r33Xt1555167rnngvuFAOBHQQdwiZMnT+qbb75RWlraRcttNpvuueceORyOH92uY8eOeuutt/TMM89o+vTpcrlcGjVqlL+ge71ebdy4UVlZWZeVo127dnI4HDpy5Ih27typ2NhY5efn689//rNuvPFGrV+/Xh06dNAtt9yiTZs2SZI++ugjxcXF6frrr2/EVwAAgOCq71x78uRJHT16VL/4xS8uea1bb71VJSUl8nq9GjhwoH9OLC0t1fHjx9W3b1+tXr1a4eHhevPNN7Vp0yb927/9m5599ln/a3Tt2lVvv/22BgwYoJdfflmLFi3Sm2++qfz8fK1evVoulysIXwUA/4pD3AFcIizs/N/uvF5vvbbLzs6WJKWkpCgpKUn79u1Tv379tGDBAh0+fFjl5eXq2LGjrrvuust+TZvNppiYGDmdTnXq1Enr1q1TWVmZPvnkE/8ehFGjRumZZ57RqFGjlJ+f788BAIBVNXSurampuWRZdXW1pPNzZmZmpubOnatx48bpjTfe0PDhwxUWFqb3339fZ86c0V/+8hf/NgkJCf7XuHAOu81m0wsvvKD3339fW7ZsUWlpqXw+nyoqKhr0PgHUD3vQAVyidevWuvbaa/W3v/3tknWPPfZYnYePX/iwIZ3/wBEREaHw8HCNHDlSGzdu1BtvvHHZe88l6ZtvvpHH41Hnzp313//933ryyScVHR2tIUOGaPDgwfL5fJKk2267TRUVFfrwww+1Z88eDRo0qJ7vGAAAY9V3rr3qqquUmJioTz755JLnf/TRR0pKSlJsbKx69eqlmpoa7d+/X1u2bNHw4cMlnZ+XZ8yYoT/96U/605/+pNdff13Lly/3v4bdbpd0/howGRkZ+vzzz3XDDTdo6tSpioiI8M+5AIKLgg7gR40fP14LFixQWVmZJKm2tlYrV67U4cOH69wD/tZbb0mSPv/8c3311Ve6+eabJZ0//23btm36/PPPNXDgwMsa//Tp03r66ac1atQoRUVFadeuXcrIyFBmZqYSExO1fft21dbWSjr/1/77779fTz75pAYPHqyoqKjGvn0AAIKuvnPtE088odzcXBUVFfmX7du3T4sWLdLjjz/uX5aZmamnn35a3bp1818Nvk+fPlq/fr2qqqrk9Xo1a9YsLVu27JIxysrK5Ha7NXHiRPXv318ff/yxfxsAwcch7gB+1JAhQ+Tz+TR58mTV1NSosrJSP/vZz7R27do6r+D+9ddfa9iwYbLZbFq2bJni4uIkSQkJCbrxxhuVlJSkFi1a1Dnm448/rujoaIWHh6u2tla//OUv9eijj0qSxo4dq9mzZ2vjxo2Szl8U58svv/Rvm5GRocWLF2vkyJFX6CsAAEBw1XeuveOOO7R48WItX75c5eXl8nq9ateunRYvXqxbbrnF/7xhw4Zp2bJlFxXwX//611q8eLEyMjJUW1ur7t27a/r06ZeM0a1bN915550aNGiQIiMjlZKSouTkZJWVlQXlDi4ALmbzcbwKgCBzuVwaMWKE1q9fX+d9XRtr69ateuutt/Tiiy8G5fUBAACAYGMPOoCgeu2117Rs2TJNmDAhaOV89OjRcrlcWrlyZVBeHwAAADACe9ABAAAAALAALhIHAAAAAIAFUNABAAAAALCAZnkOelFREbdZAgCgASorK5WamnpZz2W+BQCgYeqab5tlQY+KilL37t3NjgEAQJNz6NChy34u8y0AAA1T13zLIe4AAAAAAFgABR0AAAAAAAugoAMAAAAAYAEUdAAAAAAALICCDgAAAACABVDQAQAAAACwAAo6AAAAAAAWQEEHAAAAAMACKOgAAAAAAFgABR0AAAAAAAugoAMAAAAAYAERZgcAYKzCwkIVFBSYMrbL5ZIkxcfHmzJ+enq6nE6nKWMDAAAAgVDQARjmxIkTkswr6AAAAICVUdCBEON0Ok3bi5yTkyNJysvLM2V8AAAAwMo4Bx0AAAAAAAugoAMAAAAAYAEUdAAAAAAALICCDgAAAACABVDQAQAAAACwAAo6AAAAAAAWQEEHAAAAAMACKOgAAAAAAFgABR0AAAAAAAugoAMAAAAAYAEUdAAAAAAALICCDgAAAACABVDQAQAAAACwAAo6AAAAAAAWEGF2AAAAAABAwxQWFqqgoMCUsV0ulyQpPj7elPHT09PldDpNGTtYKOgAAAAAgHo7ceKEJPMKenNEQQcAAACAJsrpdJq2FzknJ0eSlJeXZ8r4zRHnoAMAAAAAYAEUdAAAAAAALICCDgAAAACABVDQAQAAAACwAAo6AAAAAAAWQEEHAAAAAMACKOgAAAAAAFgA90EHTJCXl6eSkhKzYxiuuLhY0v+/Z2YoSU5ODsn3DQAAgMtHQQdMUFJSoi8P/FWdHbVmRzFUrM8mSTp39FOTkxjrK3e42REAAADQBFDQAZN0dtRqZi+32TFggPl7HGZHAAAAQBPAOegAAAAAAFgABR0AAAAAAAugoAMAAAAAYAEUdAAAAAAALICCDgAAAACABRh2FXev16s5c+boiy++UGRkpObPn68uXbpc9JyKigo9+OCDWrBggZKSkiRJw4YNU6tWrSRJHTt21MKFC42KDAAAAACAYQwr6Nu2bVNVVZXy8/NVVFSkRYsWadWqVf71n332mZ566imVl5f7l1VWVkqS1q1bZ1RMAAAAAABMYVhB37t3r/r27StJSk1N1YEDBy5aX1VVpRUrVmjq1Kn+ZYcPH1ZFRYXGjh2rmpoaTZ48WampqQHHqqys1KFDh65ofuBK8ng8nF8SYjweD7+X0Oww3wJAaPN4PJLEXHAFGVbQ3W63HA6H/3F4eLhqamoUEXE+Qs+ePS/ZJjo6WuPGjVNmZqaOHj2qhx9+WIWFhf5t6hIVFaXu3btf2TcAXEF2u13nzA4BQ9ntdn4voUmoz4cs5lsACG12u12SmAsaoK751rCC7nA4dPbsWf9jr9cbsGgnJiaqS5custlsSkxMVFxcnI4dO6b27dsHOy4AAAAAAIYy7CjbtLQ07dy5U5JUVFSklJSUgNts3LhRixYtkiSVl5fL7XarTZs2Qc0JAAAAAIAZDNuDPnDgQO3evVtZWVny+XzKzc3V5s2b5fF4NHLkyB/dZsSIEXriiSeUnZ0tm82m3NzcgHvdAQAAAABoigxru2FhYZo3b95Fyy7cSu2f/fMV2yMjI7V06dKgZwMAAAAAwGxcSBoAAAAAAAugoAMAAAAAYAEUdAAAAAAALICCDgAAAACABXBJdABAUBQWFqqgoMCUsV0ulyQpPj7elPHT09PldDpNGRsAADRdFHQAQLNz4sQJSeYVdAAAgIagoAMAgsLpdJq2FzknJ0eSlJeXZ8r4AAAADcE56AAAAAAAWAAFHQAAAAAAC6CgAwAAAABgARR0AAAAAAAsgIIOAAAAAIAFUNABAAAAALAACjoAAAAAABZAQQcAAAAAwAIizA4AAAievLw8lZSUmB3DcMXFxZKknJwck5MYLzk5OSTfNwAAzQEFHQCasZKSEu37fJ8UZ3YSg/3j+LB93+wzN4fRTpkdAAAANAYFHQCauzjJe6fX7BQwQNj7nLkGAEBTxkwOAAAAAIAFUNABAAAAALAACjoAAAAAABZAQQcAAAAAwAIo6AAAAAAAWAAFHQAAAAAAC6CgAwAAAABgARR0AAAAAAAsgIIOAAAAAIAFUNABAAAAALAACjoAAAAAABZAQQcAAAAAwAIizA4AAAgel8slnZLC3ufvsSHhlOSKcZmdAgAANBAFHTCBy+XSsTPhmr/HYXYUGKDsTLjauChNAAAA+GkUdABoxuLj41VWUSbvnV6zo8AAYe+HKT4+3uwYAACggSjogAni4+NlP12qmb3cZkeBAebvcSia0gQAAIAAKOgAAAAA0Ah5eXkqKSkxO4bhiouLJUk5OTkmJzFecnJyUN43BR0AAAAAGqGkpET7Pt8nxZmdxGD/uAbtvm/2mZvDaKeC99IUdAAAAABorDhxzZcQEcy743DfHQAAAAAALICCDgAAAACABVDQAQAAAACwAAo6AAAAAAAWQEEHAAAAAMACKOgAAAAAAFhAwIK+Y8eOix4XFBQ0aCCv16vZs2dr5MiRGj16tMrKyi55TkVFhbKyslRaWnrZ2wAAAAAA0BzUeR/0HTt26K9//au2bt2qffvO33i+trZW27dvV3p6er0H2rZtm6qqqpSfn6+ioiItWrRIq1at8q//7LPP9NRTT6m8vPyytwEAAAAAoLmos6Bff/31OnXqlKKiopSYmChJstlsGjx4cIMG2rt3r/r27StJSk1N1YEDBy5aX1VVpRUrVmjq1KmXvU1dKisrdejQoQblBIzg8Xg4vyTEeDweU34veTwew8eEuYz8WWO+BYDzmG9DT7Dm2zoLevv27ZWRkaGhQ4cqLKzxVcLtdsvhcPgfh4eHq6amRhER5yP07Nmz3tvUJSoqSt27d290ZiBY7Ha7zpkdAoay2+2m/F6y2+3SScOHhYka+7NWnw8bzLcAcB7zbegJ1nz7001X0po1a7RmzRpFR0f7l+3ataveARwOh86ePet/7PV6AxbthmwDAAAAAEBTFLDtFhQU6H/+538UExPTqIHS0tK0Y8cOpaenq6ioSCkpKUHZBgAAAACApihgQb/mmmsu2nveUAMHDtTu3buVlZUln8+n3Nxcbd68WR6PRyNHjrzsbQAA9XRKCns/xK56cOEcksZPX03LKUnXmB0CAAA0VMCCXl1drSFDhiglJUU2m02StHTp0noPFBYWpnnz5l20LCkp6ZLnrVu37ie3AQBcvuTkZLMjmKK4uFiS1PWariYnMdg1ofs9BwCgOQhY0B9++GEjcgAAgiAnJ8fsCKa48L7z8vJMTgIAAHD5Ah7zeMMNN2j37t364x//qFOnTqlt27ZG5AIAAAAAIKQELOgzZsxQp06ddPToUV199dV68sknjcgFAAAAAEBICVjQT506pREjRigiIkJpaWny+XxG5AIAAAAAIKRc1mV9S0tLJUnfffedwsJC7ErAAAAAAAAYIGDbfvLJJzVjxgwdPHhQOTk5mj59uhG5AAAAAAAIKQGv4t6tWzfl5+cbkQUAAAAAgJBVZ0HPyclRXl6e+vTpc8m6Xbt2BTUUAAAAAAChps6CfuHesbt27ZLH45Hdbld5eTm3WQMAAAAAIAgCnoP+/PPP+8v6ggULtHr16qCHAgAAAAAg1AQs6Nu3b/dfGC4vL0/bt28PeigAAAAAAEJNwIJus9lUVVUlSaquruY+6AAAAAAABEHAq7hnZWVpyJAhSklJ0ZEjR/TQQw8ZkQsAAAAAgJASsKBnZmbqrrvu0tdff61OnTopPj7eiFwAAAAAAISUOgv6ypUr9etf/1qTJ0+WzWa7aN3SpUuDHgwAAAAAgFBSZ0F3OBySpGHDhik6OtqwQAAAAAAAhKI6C/qmTZs0YsQIrVmzRi+//DIXhwMAAAAAIIjqLOi9e/fWsGHD9N1338npdEqSfD6fbDab3nvvPcMCAgAAAAAQCuos6G3atNE777yj559/XuPHjzcyEwAAAAAAIafOgp6fn6+OHTvq3XffVY8ePS46xL1Pnz6GhAMAAAAAIFTUWdAfe+wxbdu2TSdOnNCWLVsuWkdBv/IKCwtVUFBgytgul0uSTLuFXnp6uv80CgAAAAAIVXUW9AEDBmjAgAHavn27+vfvrx9++EGxsbGX3HINTd+JEyckmVfQQ9VX7nDN3+MwO4ahfqg6//ujdWRoXXTyK3e4UswOAQAAAMurs6Bf4HA4NHjwYNXW1srpdKpDhw7KzMw0IltIcTqdpu1FzsnJkSTl5eWZMn4oSk5ONjuCKb4uLpYktb22q8lJjJWi0Pyem3lkUPE/ftYu/H4zGkcGAQCAhghY0JcvX67/+q//0oQJE/Too48qOzubgg40klmlwWz8MQhGSUhIMDsCAABAvQUs6GFhYYqLi5PNZlNUVJRatmxpRC4AQBNn5pFBAAAATVFYoCd07txZS5cu1cmTJ7V69Wp16NDBiFwAAAAAAISUgAV97ty56tChg3r16iW73a6nn37aiFwAAAAAAISUgAXdZrPJ6/XK5/OptrbWiEwAAAAAAIScgOegz5o1S7GxserTp48++eQTzZw5U0uWLDEiG4Ag4MranBMNAAAAawpY0MvKyrR+/XpJ5++NnpWVFfRQAJonrqwNAAAA1C1gQa+srFRFRYViYmJ07tw5DnMHmjiurA0AAABYU8CC/sADD2jo0KHq2rWrSkpKQvb+zQAAAAAABFPAgn7PPffo9ttv19dff62OHTvqqquuMiIXAAAAAAAhpc6ruLvdbv32t7+V2+1WXFycysrKNG/ePLndbiPzAQAAAAAQEuos6E899ZRuuukmtWzZUtL581ZvvPFGzZkzx6hsAAAAAACEjDoL+rfffqt///d/l81mkyRFRERo3Lhx+vrrrw0LBwAAAABAqKjzHPSwsB/v7i1atAhaGLPl5eWppKTE7BiGM/ve1GZKTk4OyfcNAAAAwHrqLOhdunTRtm3bNGDAAP+y9957T23atDEkmBlKSkq077OD8trjzY5iKFvt+R+DvaXfmZzEWGEel9kRAAAAAMCvzoI+bdo0TZ48WStWrFDHjh317bffKj4+XkuWLDEyn+G89nidu2Gw2TFggOiDW8yOAAAAAAB+dRb02NhYvfjii/r73/+u77//Xu3bt1fbtm2NzAYAAAA0SYWFhSooKDBlbJfr/FGC8fHmHBWanp4up9NpythAUxfwPugdOnRQhw4djMgCAAAAoJFOnDghybyCDqDhAhZ0AAAAAPXjdDpN24t84QK4eXl5powPoOHqvM0aAAAAAAAwTsA96Lt379Yf/vAHVVVV+Ze98sor9R7I6/Vqzpw5+uKLLxQZGan58+erS5cu/vXbt2/XihUrFBERoeHDh+u+++6TJA0bNkytWrWSJHXs2FELFy6s99gAAAAAAFhdwIK+cOFCzZgxQ+3atWvUQNu2bVNVVZXy8/NVVFSkRYsWadWqVZKk6upqLVy4UBs3blRMTIyys7PVr18/xcbGSpLWrVvXqLEBAAAAALC6gAW9ffv2uu222xo90N69e9W3b19JUmpqqg4cOOBfV1paqs6dO6t169aSpJ49e2rPnj3q0KGDKioqNHbsWNXU1Gjy5MlKTU0NOFZlZaUOHTpU74wej6fe26Bp83g8DfpZAQA0fL4FEFwXPtPy36dx6BGhJ1g9ImBBT0hI0OzZs3XDDTfIZrNJkkaOHFnvgdxutxwOh/9xeHi4ampqFBERIbfb7T+MXZJatmwpt9ut6OhojRs3TpmZmTp69KgefvhhFRYWKiLip2NHRUWpe/fu9c5ot9slna73dmi67HZ7g35WAKC5qs+HjYbOtwCC6/xnWvHfp4Hsdrt00uwUMFJje0Rd823Agt6xY0dJ0vHjxxs8uCQ5HA6dPXvW/9jr9fqL9r+uO3v2rFq1aqXExER16dJFNptNiYmJiouL07Fjx9S+fftGZQEAAAAAwGoCXsV9/PjxuvHGGxUVFaXrr79e48ePb9BAaWlp2rlzpySpqKhIKSkp/nVJSUkqKyvTqVOnVFVVpT179qhHjx7auHGjFi1aJEkqLy+X2+1WmzZtGjQ+AAAAAABWFnAP+tKlS1VWVqa0tDT98Y9/1N69ezVt2rR6DzRw4EDt3r1bWVlZ8vl8ys3N1ebNm+XxeDRy5EhNnz5d48aNk8/n0/Dhw9W2bVuNGDFCTzzxhLKzs2Wz2ZSbmxvw8HYAAAAAAJqigG33008/1YYNGyRJY8aM8d/+rL7CwsI0b968i5YlJSX5/92/f3/179//ovWRkZFaunRpg8ZrCJfLpTDPCUUf3GLYmDBPmOeEXK5Is2MAAAAAgKTLOMS9pqZGXq9XkuTz+fwXigMAAAAAAFdOwD3o6enpys7O1s0336z9+/crPT3diFymiI+P1/+erNK5GwabHQUGiD64RfHx8WbHAAAAQZKXl6eSkhKzYxiuuLhYkpSTk2NyEuMlJyeH5PtG8xGwoI8dO1Z9+vTRkSNHNGLEiIsu7gYAAABYVUlJib488Fd1dtSaHcVQsb7zR7yeO/qpyUmM9ZU73OwIQKPVWdBff/11ZWZmaunSpf7D2g8ePChJmjx5sjHpAAAAgEbo7KjVzF5us2PAAPP3OMyOADRanQW9Xbt2kqTrrrvuouWcgw4AAAAAwJVX50Xi+vbtK0n67LPPlJGR4f/fX/7yF8PCAQAAAAAQKurcg75+/XqtWrVKP/zwg9555x3/8n++NRoAAAAAhDqXyyWdksLeD3iTLDQHpyRXjCsoL11nQR81apRGjRqlF154QY8++mhQBgcAAAAAAOcFvIp7VlaWtmzZopqaGvl8Pn3//ff6j//4DyOyAQAAAIDlxcfHq6yiTN47vWZHgQHC3g8L2u2aAxb0nJwcXXvttfryyy8VFRWlmJiYoAQBAAAAACCUBSzokjRv3jw98cQTWrBggUaNGhXsTKYK87gUfXCL2TEMZauukCT5WoTWH1/CPC5J7cyOAQAAAACSLrOgV1ZWqqKiQjabTR6PJ9iZTJOcnGx2BFMUFxdLkromhVpZbRey33MAAAAA1hOwoI8aNUr/+Z//qd69e+uOO+5Qz549jchlipycHLMjmOLC+87LyzM5CQAAAACEroAF/e677/b/e9CgQXI4HEENBAAAAABAKApY0Dds2KANGzaoqqrKv6ygoCCooQAAAAAACDUBC/orr7yi1atXq3Xr1kbkAQAAAAAgJAUs6N26dVP79u0VHh5uRB4AAAAAAEJSwIJ+yy23aMCAAerUqZN8Pp9sNpteeeUVI7IBAAAAABAyAhb0/Px8Pffcc2rVqpUReUJWYWGhaef2X7jNmllXsU9PT5fT6TRlbAAAAACwioAFvW3btrrpppsUFhZmRB6YICEhwewIAAAAABDyAhb0qqoqDR06VF27dpXNZpMkLV26NOjBQo3T6WQvMgAAzdjx48c1d+5czZkzhz+OAwB+VMCCnp2drdjYWCOyAAAANFtr167V/v37tXbtWk2ePNnsOAAACwpY0F966SW9+uqrRmQBAABolo4fP663335bPp9Pb7/9tsaMGcNedADAJQKeWN66dWutXbtWO3fu1K5du7Rr1y4jcgEAADQba9eulc/nkyR5vV6tXbvW5EQAACsKuAf9qquu0uHDh3X48GH/sj59+gQ1FAAAQHPy7rvvqrq6WpJUXV2td955h8PcAQCXCFjQFy5cqC+//FIlJSVKTExU9+7djcgFAADQbAwcOFAFBQWqrq5WixYt9Mtf/tLsSAAACwp4iPu6des0a9Ys7du3T7NmzdJLL71kRC4AAIBmY8yYMf674YSFhWnMmDEmJwIAWFHAPehbtmzR+vXrFRERoerqamVlZWncuHFGZAMAAGgWrr76ag0aNEibNm3SoEGDuEAcAOBHBSzoPp9PERHnn9aiRQu1aNEi6KEAAACamzFjxujo0aPsPQcA1ClgQU9LS1NOTo569uypvXv3qkePHkbkAgAAaFauvvpq/f73vzc7BgDAwuo8B/3TTz+VJE2aNEn33nuvampqdO+992ratGmGhQMAAAAAIFTUWdAXL14sj8ejhx56SL1799bo0aN12223qaqqysh8AAAAAACEhDoPce/du7eGDRum7777Tk6nU9L589FtNpvee+89wwICAAAAABAK6izokyZN0qRJk7RixQr95je/MTITAAAA0Ggul0vHzoRr/h6H2VFggLIz4WrjcpkdA2iUgBeJy8jI0Jo1a1RZWelfNn78+KCGAgAAAAAg1AQs6BMnTtStt96q9u3bG5EHAAAAuCLi4+NlP12qmb3cZkeBAebvcSg6Pt7sGECjBCzoLVu21KRJk4zIAgAAAABAyApY0Lt27aqtW7eqe/fustlskqTExMSgBwMAAAAAIJQELOiHDh3SoUOH/I9tNpteeeWVoIYCAAAAACDUBCzo69atMyIHAAAAAAAhrc6CPnLkSP8h7f9qw4YNQQsEAAAAAEAoqrOgL1u2zMgcAAAAAACEtDoL+jXXXGNkDgAAAAAAQlrAc9CvFK/Xqzlz5uiLL75QZGSk5s+fry5duvjXb9++XStWrFBERISGDx+u++67L+A2AACg6cnLy1NJSYkpY7tcLp04ccKUsc2WkJCgeJPuEZ2cnKycnBxTxgaApsSwgr5t2zZVVVUpPz9fRUVFWrRokVatWiVJqq6u1sKFC7Vx40bFxMQoOztb/fr10759++rcBgAANE0lJSXa99lBee3Gl0VbdYVs1VWGj2sFZ77/Qf970vj3HuZxGT4mADRVhhX0vXv3qm/fvpKk1NRUHThwwL+utLRUnTt3VuvWrSVJPXv21J49e1RUVFTnNj+lsrLyolvDAQCAK6+h863H45HXHq9zNwwOQipYTfTBLfJ4PKZ8NvN4PAozfFSYycyfNYSWYP2sGVbQ3W63HA6H/3F4eLhqamoUEREht9utVq1a+de1bNlSbrf7J7f5KVFRUerevfuVfxMAADRz9fmw0dD51m63Szpd7+3QdNntdlM+m9ntdp0zfFSYycyfNZ00fFiYqLE/a3XNt4b9UdHhcOjs2bP+x16v11+0/3Xd2bNn1apVq5/cBgAAAACA5sSwgp6WlqadO3dKkoqKipSSkuJfl5SUpLKyMp06dUpVVVXas2ePevTo8ZPbAAAAAADQnBi2O3rgwIHavXu3srKy5PP5lJubq82bN8vj8WjkyJGaPn26xo0bJ5/Pp+HDh6tt27Y/ug0AAAAAAM2RYQU9LCxM8+bNu2hZUlKS/9/9+/dX//79A24DAAAAAEBzxAndAADAUC6XS2GeE4o+uMXsKDBAmOeEXK5Is2MAQJPAnScAAAAAALAA9qADAABDxcfH639PVnEf9BARfXCL4uPjzY4BAE0Ce9ABAAAAALAA9qADAADDhXlcIXcOuq26QpLkaxFjchJjhXlcktqZHQMAmgQKOgAAMFRycrLZEUxRXFwsSeqaFGpltV3Ifs8BoL4o6AAAwFA5OTlmRzDFhfedl5dnchIAgFVxDjoAAAAAABZAQQcAAAAAwAIo6AAAAAAAWADnoAMAgJBRWFiogoICU8a+cJE4s87BT09Pl9PpNGVsAMDloaADAAAYICEhwewIAACLo6ADAICQ4XQ62YscYr5yh2v+HofZMQz1Q5VNktQ60mdyEmN95Q5XitkhgEaioAMAAKBZCtX7r3/9j9Mp2l7b1eQkxkpR6H7P0XxQ0AEAANAsmXW+v9kuvO+8vDyTkwCoL67iDgAAAACABVDQAQAAAACwAAo6AAAAAAAWQEEHAAAAAMACKOgAAAAAAFgAV3EHAAAArrDCwkIVFBSYMnbxP26zZtZV7NPT0+V0Ok0ZG2jqKOgAAABAM5KQkGB2BAANREEHAAAArjCn08leZAD1xjnoAAAAAABYAAUdAAAAAAALoKADAAAAAGABnIMOAAAAAI11Sgp7P8T2f577x/9Hm5rCeKckXROcl6agAwAAAEAjJCcnmx3BFBdu6df1mq4mJzHYNcH7nlPQAQAAAKARzLrnvNkuvO+8vDyTkzQfIXYMBgAAAAAA1kRBBwAAAADAAijoAAAAAABYAAUdAAAAAAALoKADAAAAAGABFHQAAAAAACyAgg4AAAAAgAVQ0AEAAAAAsAAKOgAAAAAAFkBBBwAAAADAAijoAAAAAABYAAUdAAAAAAALoKADAAAAAGABFHQAAAAAACwgwqiBzp07pylTpujEiRNq2bKlFi9erPj4+Iue89prr2nDhg2KiIjQr371K/Xr108+n0+33367rr32WklSamqqfvvb3xoVGwAAAAAAQxhW0F999VWlpKRowoQJ2rp1q1auXKmZM2f61x87dkzr1q3TG2+8ocrKSt1///3q3bu3vv32W/3sZz/TCy+8YFRUAAAAAAAMZ1hB37t3rx566CFJ0u23366VK1detH7//v3q0aOHIiMjFRkZqc6dO+vw4cP6v//7P5WXl2v06NGKjo7WE088oeuuu+4nx6qsrNShQ4eC9l4AAADzLQCEOo/HI0nMBVdQUAr666+/rrVr1160LCEhQa1atZIktWzZUmfOnLlovdvt9q+/8By32602bdrokUce0aBBg7Rnzx5NmTJFb7zxxk+OHxUVpe7du1+hdwMAQOioz4cs5lsACG12u12SmAsaoK75NigFPTMzU5mZmRctGz9+vM6ePStJOnv2rGJjYy9a73A4/OsvPKdVq1ZKTk5WeHi4JKlXr14qLy+Xz+eTzWYLRnQAAAAAAExh2FXc09LS9MEHH0iSdu7cqZ49e160/uc//7n27t2ryspKnTlzRqWlpUpJSdHzzz/v3xt/+PBhdejQgXIOAAAAAGh2DDsHPTs7W9OmTVN2drZatGihpUuXSpL+8Ic/qHPnzrrrrrs0evRo3X///fL5fJo0aZKioqL0yCOPaMqUKfrggw8UHh6uhQsXGhUZAAAAAADDGFbQY2JilJeXd8nyBx980P/v++67T/fdd99F61u3bq3Vq1cHPR8AAAAAAGYy7BB3AAAAAABQNwo6AAAAAAAWQEEHAAAAAMACKOgAAAAAAFgABR0AAAAAAAugoAMAAAAAYAEUdAAAAAAALICCDgAAAACABVDQAQAAAACwAAo6AAAAAAAWQEEHAAAAAMACKOgAAAAAAFgABR0AAAAAAAugoAMAAAAAYAEUdAAAAAAALICCDgAAAACABVDQAQAAAACwAAo6AAAAAAAWQEEHAAAAAMACKOgAAAAAAFgABR0AAAAAAAuIMDsAAAAAAKBhCgsLVVBQYMrYxcXFkqScnBxTxk9PT5fT6TRl7GChoAMAAAAA6i0hIcHsCM0OBR0AAAAAmiin09ns9iKHMs5BBwAAAADAAijoAAAAAABYAAUdAAAAAAALoKADAAAAAGABFHQAAAAAACyAgg4AAAAAgAVQ0AEAAAAAsAAKOgAAAAAAFkBBBwAAAADAAijoAAAAAABYAAUdAAAAAAALoKADAAAAAGABEWYHCIbKykodOnTI7BgAADQ5lZWV9Xou8y0AAPVX13xr8/l8PoOzAAAAAACAf8Eh7gAAAAAAWAAFHQAAAAAAC6CgAwAAAABgARR0AAAAAAAsgIIOAAAAAIAFUNABAAAAALCAZnkfdNTf3/72Nz377LNat26d2VHQjA0bNkytWrWSJHXs2FELFy40ORGai+rqas2YMUPffPONqqqq9Ktf/Up33XWXJCk3N1eJiYnKzs42OSVCHXMtjMJ8i2Bhvg0+Cjq0Zs0abdq0STExMWZHQTNWWVkpSXwwRVBs2rRJcXFxeuaZZ3Ty5EllZGSoR48emjp1qo4ePapx48aZHREhjrkWRmG+RTAx3wYfh7hDnTt31u9//3uzY6CZO3z4sCoqKjR27Fg98MADKioqMjsSmhGn06nHHnvM/zg8PFxnz57VhAkTNHToUBOTAecx18IozLcIJubb4KOgQ3fffbciIjiYAsEVHR2tcePG6aWXXtLcuXP1+OOPq6amxuxYaCZatmwph8Mht9utnJwcTZw4UZ06ddLNN99sdjRAEnMtjMN8i2Bivg0+CjoAQyQmJuqee+6RzWZTYmKi4uLidOzYMbNjoRn59ttv9cADD2jo0KEaMmSI2XEAwBTMtwg25tvgoqADMMTGjRu1aNEiSVJ5ebncbrfatGljcio0F8ePH9fYsWM1ZcoUjRgxwuw4AGAa5lsEE/Nt8FHQARhixIgROnPmjLKzszVp0iTl5uZyuCeumBdeeEGnT5/WypUrNXr0aI0ePVrnzp0zOxYAGI75FsHEfBt8Np/P5zM7BAAAAAAAoY496AAAAAAAWAAFHQAAAAAAC6CgAwAAAABgARR0AAAAAAAsgIIOAAAAAIAFUNAB/Kg333xTzz77bL226d+/vyorKwM+7+OPP9akSZMaGu0SO3fu1PTp06/Y6wEAYBTmWwD/jIIOAAAAAIAFRJgdAIC1vfzyy9q6dasiIiLUq1cvTZkyRadPn9aUKVPkdrtVW1urxx57TLfeeqt/m1dffVW7d+/WsmXLtH37dq1fv96/bvny5ZKksrIyPfTQQ3K5XOrXr58mTJigL774QvPnz5ckxcXFKTc3V3a7XbNnz9Z3332nkydP6vbbb9fEiRNVWlqqGTNmKCYmRjExMWrdurWxXxgAAK4g5lsAEgUdwE8oKyvTxx9/rA0bNigiIkITJkzQjh079Mknn+i2227TmDFjVF5eruzsbG3btk2StG7dOh06dEjLly9XeHi4jh49qtWrVysmJkazZ8/Wrl271LZtW1VWVmrlypWqra3VnXfeqQkTJmjWrFnKzc1VcnKyXn/9db344ovKzMxUamqqMjMzVVlZ6f/AsHz5cuXk5Kh3795avXq1jhw5YvJXCwCAhmG+BXABBR1AnQ4dOqQ777xTLVq0kCT16tVLxcXFKi0t1ZAhQyRJbdu2lcPhkMvlkiR9+OGHCg8PV3h4uCQpISFB06ZNU8uWLXXkyBGlpqZKkrp27arIyEhJUkTE+V9FpaWlmjt3riSpurpaiYmJiouL02effaaPPvpIDodDVVVVkqTi4mL9/Oc/lySlpaXxgQEA0GQx3wK4gHPQAdSpe/fu2r9/v2pqauTz+fTpp58qMTFRSUlJ2rNnjySpvLxcp0+fVlxcnCRp5cqVio2N1auvvqozZ84oLy9Pv/vd7zR//nxFRUXJ5/NJkmw22yXjJSYmavHixVq3bp2mTJmiO+64Q2+++aZatWqlpUuXauzYsTp37px8Pp+uu+467du3T5J04MABY74gAAAEAfMtgAvYgw6gTl26dFFaWpqys7Pl9XrVs2dPDRgwQL/4xS80Y8YM/fnPf9a5c+c0b948/1/lJWnmzJnKzMzUrbfeqrS0NGVkZMhutys2Nlbff/+9Onbs+KPjzZkzR9OmTVNtba0kacGCBUpKStLkyZO1d+9excTEqEuXLvr+++/11FNPadKkSXrppZcUHx+vqKgoQ74mAABcacy3AC6w+S78eQ0AAAAAAJiGQ9wBAAAAALAACjoAAAAAABZAQQcAAAAAwAIo6AAAAAAAWAAFHQAAAAAAC6CgAwAAAABgARR0AAAAAAAs4P8B8KdJ8Tq7eBcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1008x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(14,5), sharey=True)\n",
    "\n",
    "# plot average of daily IC values\n",
    "sns.boxplot(x='lookahead', y='ic_by_day',data=lr_metrics, ax=axes[0])\n",
    "axes[0].set_title('IC by Day')\n",
    "\n",
    "# plot IC across all predictions\n",
    "sns.boxplot(x='lookahead', y='ic',data=lr_metrics, ax=axes[1])\n",
    "axes[1].set_title('IC Overall')\n",
    "axes[0].set_ylabel('Information Coefficient')\n",
    "axes[1].set_ylabel('')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Train/Test Period Lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one- and five-day return forecasts, shorter train- and test-length yield better results in terms of daily avg IC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.911949Z",
     "start_time": "2020-06-21T03:19:37.898655Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lookahead</th>\n",
       "      <th>train_length</th>\n",
       "      <th>test_length</th>\n",
       "      <th>ic_by_day</th>\n",
       "      <th>ic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>252</td>\n",
       "      <td>21</td>\n",
       "      <td>0.073565</td>\n",
       "      <td>-0.008878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1134</td>\n",
       "      <td>21</td>\n",
       "      <td>0.053270</td>\n",
       "      <td>-0.004830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>252</td>\n",
       "      <td>63</td>\n",
       "      <td>0.036495</td>\n",
       "      <td>-0.015929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>252</td>\n",
       "      <td>21</td>\n",
       "      <td>0.185994</td>\n",
       "      <td>-0.026527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1134</td>\n",
       "      <td>21</td>\n",
       "      <td>0.150933</td>\n",
       "      <td>-0.016188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1134</td>\n",
       "      <td>63</td>\n",
       "      <td>0.075325</td>\n",
       "      <td>0.054850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21</td>\n",
       "      <td>1134</td>\n",
       "      <td>21</td>\n",
       "      <td>0.139943</td>\n",
       "      <td>-0.016514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21</td>\n",
       "      <td>252</td>\n",
       "      <td>21</td>\n",
       "      <td>0.124666</td>\n",
       "      <td>-0.077621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21</td>\n",
       "      <td>1134</td>\n",
       "      <td>63</td>\n",
       "      <td>0.104136</td>\n",
       "      <td>0.091128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lookahead  train_length  test_length  ic_by_day        ic\n",
       "3           1           252           21   0.073565 -0.008878\n",
       "1           1          1134           21   0.053270 -0.004830\n",
       "2           1           252           63   0.036495 -0.015929\n",
       "7           5           252           21   0.185994 -0.026527\n",
       "5           5          1134           21   0.150933 -0.016188\n",
       "4           5          1134           63   0.075325  0.054850\n",
       "9          21          1134           21   0.139943 -0.016514\n",
       "11         21           252           21   0.124666 -0.077621\n",
       "8          21          1134           63   0.104136  0.091128"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lr_metrics.groupby('lookahead', group_keys=False)\n",
    " .apply(lambda x: x.nlargest(3, 'ic_by_day')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.920850Z",
     "start_time": "2020-06-21T03:19:37.913179Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_metrics.to_csv(results_path / 'lin_reg_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook example iterates over many configurations, optionally using random samples to speed up model selection using a diverse subset. The goal is to identify the most impactful parameters without trying every possible combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.935808Z",
     "start_time": "2020-06-21T03:19:37.921761Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_fi(model):\n",
    "    \"\"\"Return normalized feature importance as pd.Series\"\"\"\n",
    "    fi = model.feature_importance(importance_type='gain')\n",
    "    return (pd.Series(fi / fi.sum(),\n",
    "                      index=model.feature_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `base_params` are not affected by cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.943601Z",
     "start_time": "2020-06-21T03:19:37.936926Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_params = dict(boosting='gbdt',\n",
    "                   objective='regression',\n",
    "                   verbose=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the following parameters and values to select our best model (see book chapter for detail):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.952308Z",
     "start_time": "2020-06-21T03:19:37.944671Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# constraints on structure (depth) of each tree\n",
    "max_depths = [2, 3, 5, 7]\n",
    "num_leaves_opts = [2 ** i for i in max_depths]\n",
    "min_data_in_leaf_opts = [250, 500, 1000]\n",
    "\n",
    "# weight of each new tree in the ensemble\n",
    "learning_rate_ops = [.01, .1, .3]\n",
    "\n",
    "# random feature selection\n",
    "feature_fraction_opts = [.3, .6, .95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.960258Z",
     "start_time": "2020-06-21T03:19:37.953744Z"
    }
   },
   "outputs": [],
   "source": [
    "param_names = ['learning_rate', 'num_leaves',\n",
    "               'feature_fraction', 'min_data_in_leaf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.969006Z",
     "start_time": "2020-06-21T03:19:37.961383Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_params = list(product(learning_rate_ops,\n",
    "                         num_leaves_opts,\n",
    "                         feature_fraction_opts,\n",
    "                         min_data_in_leaf_opts))\n",
    "n_params = len(cv_params)\n",
    "print(f'# Parameters: {n_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Period Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.977749Z",
     "start_time": "2020-06-21T03:19:37.969903Z"
    }
   },
   "outputs": [],
   "source": [
    "lookaheads = [1, 5, 21]\n",
    "label_dict = dict(zip(lookaheads, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only use test periods of 63 days length to save some model training and evaluation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.986465Z",
     "start_time": "2020-06-21T03:19:37.978744Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_lengths = [int(4.5 * 252), 252]\n",
    "test_lengths = [63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.995277Z",
     "start_time": "2020-06-21T03:19:37.987379Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_params = list(product(lookaheads, train_lengths, test_lengths))\n",
    "n = len(test_params)\n",
    "test_param_sample = np.random.choice(list(range(n)), size=int(n), replace=False)\n",
    "test_params = [test_params[i] for i in test_param_sample]\n",
    "print('Train configs:', len(test_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We integer-encode categorical variables with values starting at zero, as expected by LightGBM (not necessary\n",
    "as long as the category codes have values less than $2^{32}$, but avoids a warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:38.043537Z",
     "start_time": "2020-06-21T03:19:37.996178Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categoricals = ['year', 'weekday', 'month']\n",
    "for feature in categoricals:\n",
    "    data[feature] = pd.factorize(data[feature], sort=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Loss Function: Information Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:38.046578Z",
     "start_time": "2020-06-21T03:19:38.044405Z"
    }
   },
   "outputs": [],
   "source": [
    "def ic_lgbm(preds, train_data):\n",
    "    \"\"\"Custom IC eval metric for lightgbm\"\"\"\n",
    "    is_higher_better = True\n",
    "    return 'ic', spearmanr(preds, train_data.get_label())[0], is_higher_better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore the hyperparameter space, we specify values for key parameters that we would like to test in combination. The sklearn library supports `RandomizedSearchCV` to cross-validate a subset of parameter combinations that are sampled randomly from specified distributions. We will implement a custom version that allows us to monitor performance so we can abort the search process once we're satisfied with the result, rather than specifying a set number of iterations beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:38.054547Z",
     "start_time": "2020-06-21T03:19:38.047670Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lgb_store = Path(results_path / 'tuning_lgb.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:38.070171Z",
     "start_time": "2020-06-21T03:19:38.055637Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = sorted(data.filter(like='fwd').columns)\n",
    "features = data.columns.difference(labels).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:38.078077Z",
     "start_time": "2020-06-21T03:19:38.071079Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_dict = dict(zip(lookaheads, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:38.086476Z",
     "start_time": "2020-06-21T03:19:38.078921Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_iterations = [10, 25, 50, 75] + list(range(100, 501, 50))\n",
    "num_boost_round = num_iterations[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:38.094204Z",
     "start_time": "2020-06-21T03:19:38.087354Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric_cols = (param_names + ['t', 'daily_ic_mean', 'daily_ic_mean_n',\n",
    "                              'daily_ic_median', 'daily_ic_median_n'] +\n",
    "               [str(n) for n in num_iterations])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate over our six CV configurations and collect the resulting metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T11:56:42.000694Z",
     "start_time": "2020-06-21T03:19:38.095078Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for lookahead, train_length, test_length in test_params:\n",
    "    # randomized grid search\n",
    "    cvp = np.random.choice(list(range(n_params)),\n",
    "                           size=int(n_params / 2),\n",
    "                           replace=False)\n",
    "    cv_params_ = [cv_params[i] for i in cvp]\n",
    "\n",
    "    # set up cross-validation\n",
    "    n_splits = int(2 * YEAR / test_length)\n",
    "    print(f'Lookahead: {lookahead:2.0f} | '\n",
    "          f'Train: {train_length:3.0f} | '\n",
    "          f'Test: {test_length:2.0f} | '\n",
    "          f'Params: {len(cv_params_):3.0f} | '\n",
    "          f'Train configs: {len(test_params)}')\n",
    "\n",
    "    # time-series cross-validation\n",
    "    cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                              lookahead=lookahead,\n",
    "                              test_period_length=test_length,\n",
    "                              train_period_length=train_length)\n",
    "\n",
    "    label = label_dict[lookahead]\n",
    "    outcome_data = data.loc[:, features + [label]].dropna()\n",
    "    \n",
    "    # binary dataset\n",
    "    lgb_data = lgb.Dataset(data=outcome_data.drop(label, axis=1),\n",
    "                           label=outcome_data[label],\n",
    "                           categorical_feature=categoricals,\n",
    "                           free_raw_data=False)\n",
    "    T = 0\n",
    "    predictions, metrics, feature_importance, daily_ic = [], [], [], []\n",
    "    \n",
    "    # iterate over (shuffled) hyperparameter combinations\n",
    "    for p, param_vals in enumerate(cv_params_):\n",
    "        key = f'{lookahead}/{train_length}/{test_length}/' + '/'.join([str(p) for p in param_vals])\n",
    "        params = dict(zip(param_names, param_vals))\n",
    "        params.update(base_params)\n",
    "\n",
    "        start = time()\n",
    "        cv_preds, nrounds = [], []\n",
    "        ic_cv = defaultdict(list)\n",
    "        \n",
    "        # iterate over folds\n",
    "        for i, (train_idx, test_idx) in enumerate(cv.split(X=outcome_data)):\n",
    "            \n",
    "            # select train subset\n",
    "            lgb_train = lgb_data.subset(used_indices=train_idx.tolist(),\n",
    "                                       params=params).construct()\n",
    "            \n",
    "            # train model for num_boost_round\n",
    "            model = lgb.train(params=params,\n",
    "                              train_set=lgb_train,\n",
    "                              num_boost_round=num_boost_round,\n",
    "                              verbose_eval=False)\n",
    "            # log feature importance\n",
    "            if i == 0:\n",
    "                fi = get_fi(model).to_frame()\n",
    "            else:\n",
    "                fi[i] = get_fi(model)\n",
    "\n",
    "            # capture predictions\n",
    "            test_set = outcome_data.iloc[test_idx, :]\n",
    "            X_test = test_set.loc[:, model.feature_name()]\n",
    "            y_test = test_set.loc[:, label]\n",
    "            y_pred = {str(n): model.predict(X_test, num_iteration=n) for n in num_iterations}\n",
    "            \n",
    "            # record predictions for each fold\n",
    "            cv_preds.append(y_test.to_frame('y_test').assign(**y_pred).assign(i=i))\n",
    "        \n",
    "        # combine fold results\n",
    "        cv_preds = pd.concat(cv_preds).assign(**params)\n",
    "        predictions.append(cv_preds)\n",
    "        \n",
    "        # compute IC per day\n",
    "        by_day = cv_preds.groupby(level='date')\n",
    "        ic_by_day = pd.concat([by_day.apply(lambda x: spearmanr(x.y_test, x[str(n)])[0]).to_frame(n)\n",
    "                               for n in num_iterations], axis=1)\n",
    "        daily_ic_mean = ic_by_day.mean()\n",
    "        daily_ic_mean_n = daily_ic_mean.idxmax()\n",
    "        daily_ic_median = ic_by_day.median()\n",
    "        daily_ic_median_n = daily_ic_median.idxmax()\n",
    "        \n",
    "        # compute IC across all predictions\n",
    "        ic = [spearmanr(cv_preds.y_test, cv_preds[str(n)])[0] for n in num_iterations]\n",
    "        t = time() - start\n",
    "        T += t\n",
    "        \n",
    "        # collect metrics\n",
    "        metrics = pd.Series(list(param_vals) +\n",
    "                            [t, daily_ic_mean.max(), daily_ic_mean_n, daily_ic_median.max(), daily_ic_median_n] + ic,\n",
    "                            index=metric_cols)\n",
    "        msg = f'\\t{p:3.0f} | {format_time(T)} ({t:3.0f}) | {params[\"learning_rate\"]:5.2f} | '\n",
    "        msg += f'{params[\"num_leaves\"]:3.0f} | {params[\"feature_fraction\"]:3.0%} | {params[\"min_data_in_leaf\"]:4.0f} | '\n",
    "        msg += f' {max(ic):6.2%} | {ic_by_day.mean().max(): 6.2%} | {daily_ic_mean_n: 4.0f} | {ic_by_day.median().max(): 6.2%} | {daily_ic_median_n: 4.0f}'\n",
    "        print(msg)\n",
    "\n",
    "        # persist results for given CV run and hyperparameter combination\n",
    "        metrics.to_hdf(lgb_store, 'metrics/' + key)\n",
    "        ic_by_day.assign(**params).to_hdf(lgb_store, 'daily_ic/' + key)\n",
    "        fi.T.describe().T.assign(**params).to_hdf(lgb_store, 'fi/' + key)\n",
    "        cv_preds.to_hdf(lgb_store, 'predictions/' + key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat a similar process for CatBoost - see book and CatBoost [docs](https://catboost.ai/docs/concepts/about.html) for detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T11:56:42.002366Z",
     "start_time": "2020-06-21T03:17:13.861Z"
    }
   },
   "outputs": [],
   "source": [
    "param_names = ['max_depth', 'min_child_samples']\n",
    "\n",
    "max_depth_opts = [3, 5, 7, 9]\n",
    "min_child_samples_opts = [20, 250, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T11:56:42.002915Z",
     "start_time": "2020-06-21T03:17:14.083Z"
    }
   },
   "outputs": [],
   "source": [
    "cv_params = list(product(max_depth_opts,\n",
    "                         min_child_samples_opts))\n",
    "n_params = len(cv_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Period Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T11:56:42.003547Z",
     "start_time": "2020-06-21T03:17:14.456Z"
    }
   },
   "outputs": [],
   "source": [
    "lookaheads = [1, 5, 21]\n",
    "label_dict = dict(zip(lookaheads, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T11:56:42.004201Z",
     "start_time": "2020-06-21T03:17:16.556Z"
    }
   },
   "outputs": [],
   "source": [
    "train_lengths = [int(4.5 * 252), 252]\n",
    "test_lengths = [63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T11:56:42.004875Z",
     "start_time": "2020-06-21T03:17:17.116Z"
    }
   },
   "outputs": [],
   "source": [
    "test_params = list(product(lookaheads,\n",
    "                           train_lengths,\n",
    "                           test_lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T11:56:42.005692Z",
     "start_time": "2020-06-21T03:17:18.773Z"
    }
   },
   "outputs": [],
   "source": [
    "class CatBoostIC(object):\n",
    "    \"\"\"Custom IC eval metric for CatBoost\"\"\"\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        # Returns whether great values of metric are better\n",
    "        return True\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        target = np.array(target)\n",
    "        approxes = np.array(approxes).reshape(-1)\n",
    "        rho = spearmanr(approxes, target)[0]\n",
    "        return rho, 1\n",
    "\n",
    "    def get_final_error(self, error, weight):\n",
    "        # Returns final value of metric based on error and weight\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T11:56:42.006427Z",
     "start_time": "2020-06-21T03:17:29.495Z"
    }
   },
   "outputs": [],
   "source": [
    "cb_store = Path(results_path / 'tuning_catboost.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T11:56:42.007167Z",
     "start_time": "2020-06-21T03:17:29.677Z"
    }
   },
   "outputs": [],
   "source": [
    "num_iterations = [10, 25, 50, 75] + list(range(100, 1001, 100))\n",
    "num_boost_round = num_iterations[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T11:56:42.007861Z",
     "start_time": "2020-06-21T03:17:29.812Z"
    }
   },
   "outputs": [],
   "source": [
    "metric_cols = (param_names + ['t', 'daily_ic_mean', 'daily_ic_mean_n',\n",
    "                              'daily_ic_median', 'daily_ic_median_n'] +\n",
    "               [str(n) for n in num_iterations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T11:56:42.008624Z",
     "start_time": "2020-06-21T03:17:30.033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lookahead:  1 | Train: 1134 | Test: 63 | Params:  12 | Train configs: 6\n",
      "  0 | 00:09:45 (585) |   9 |  250 |  -1.00% |  1.76% |   25 |  3.40% |   25\n",
      "  1 | 00:18:56 (551) |   9 |   20 |  -1.00% |  1.76% |   25 |  3.40% |   25\n",
      "  2 | 00:23:25 (269) |   3 |   20 |  -0.15% |  1.18% |  200 |  1.44% |   75\n",
      "  3 | 00:30:51 (446) |   7 |  500 |  -0.51% |  0.67% |  800 |  0.87% |   25\n",
      "  4 | 00:36:57 (366) |   5 |  500 |   0.52% |  1.23% |   75 |  1.55% |  100\n",
      "  5 | 00:41:21 (264) |   3 |  500 |  -0.15% |  1.18% |  200 |  1.44% |   75\n",
      "  6 | 00:46:25 (305) |   3 |  250 |  -0.15% |  1.18% |  200 |  1.44% |   75\n",
      "  7 | 00:58:60 (754) |   9 |  500 |  -1.00% |  1.76% |   25 |  3.40% |   25\n",
      "  8 | 01:06:29 (449) |   5 |  250 |   0.52% |  1.23% |   75 |  1.55% |  100\n",
      "  9 | 01:13:44 (435) |   7 |  250 |  -0.51% |  0.67% |  800 |  0.87% |   25\n",
      " 10 | 01:19:44 (360) |   5 |   20 |   0.52% |  1.23% |   75 |  1.55% |  100\n",
      " 11 | 01:27:16 (451) |   7 |   20 |  -0.51% |  0.67% |  800 |  0.87% |   25\n",
      "Lookahead:  1 | Train: 252 | Test: 63 | Params:  12 | Train configs: 6\n",
      "  0 | 00:04:28 (268) |   9 |  250 |   3.05% |  0.86% |   10 |  0.95% |   75\n",
      "  1 | 00:08:56 (268) |   9 |   20 |   3.05% |  0.86% |   10 |  0.95% |   75\n",
      "  2 | 00:10:52 (116) |   3 |   20 |   3.05% |  0.87% |   10 |  1.01% |   25\n",
      "  3 | 00:14:16 (205) |   7 |  500 |   3.06% |  0.97% |   10 |  0.80% |   25\n",
      "  4 | 00:17:41 (204) |   7 |   20 |   3.06% |  0.97% |   10 |  0.80% |   25\n",
      "  5 | 00:20:23 (163) |   5 |   20 |   2.92% |  1.17% |   50 |  0.98% |  200\n",
      "  6 | 00:22:21 (118) |   3 |  250 |   3.05% |  0.87% |   10 |  1.01% |   25\n",
      "  7 | 00:25:05 (164) |   5 |  250 |   2.92% |  1.17% |   50 |  0.98% |  200\n",
      "  8 | 00:27:47 (163) |   5 |  500 |   2.92% |  1.17% |   50 |  0.98% |  200\n",
      "  9 | 00:29:45 (118) |   3 |  500 |   3.05% |  0.87% |   10 |  1.01% |   25\n",
      " 10 | 00:34:19 (274) |   9 |  500 |   3.05% |  0.86% |   10 |  0.95% |   75\n",
      " 11 | 00:37:43 (204) |   7 |  250 |   3.06% |  0.97% |   10 |  0.80% |   25\n",
      "Lookahead:  5 | Train: 1134 | Test: 63 | Params:  12 | Train configs: 6\n",
      "  0 | 00:07:38 (458) |   7 |  250 |   0.44% | -0.72% |   75 | -0.53% |   50\n",
      "  1 | 00:13:57 (380) |   5 |  250 |  -1.15% | -0.63% |   75 | -0.24% |  300\n",
      "  2 | 00:23:19 (561) |   9 |  250 |   0.10% | -0.72% |  800 | -0.04% |  300\n",
      "  3 | 00:29:39 (380) |   5 |   20 |  -1.15% | -0.63% |   75 | -0.24% |  300\n",
      "  4 | 00:34:04 (265) |   3 |  250 |  -3.77% |  1.18% |   50 |  0.42% |   50\n",
      "  5 | 00:41:42 (458) |   7 |   20 |   0.44% | -0.72% |   75 | -0.53% |   50\n",
      "  6 | 00:46:06 (264) |   3 |  500 |  -3.77% |  1.18% |   50 |  0.42% |   50\n",
      "  7 | 00:50:29 (263) |   3 |   20 |  -3.77% |  1.18% |   50 |  0.42% |   50\n",
      "  8 | 00:58:12 (463) |   7 |  500 |   0.44% | -0.72% |   75 | -0.53% |   50\n",
      "  9 | 01:04:34 (381) |   5 |  500 |  -1.15% | -0.63% |   75 | -0.24% |  300\n",
      " 10 | 01:13:56 (563) |   9 |   20 |   0.10% | -0.72% |  800 | -0.04% |  300\n",
      " 11 | 01:23:19 (563) |   9 |  500 |   0.10% | -0.72% |  800 | -0.04% |  300\n",
      "Lookahead:  5 | Train: 252 | Test: 63 | Params:  12 | Train configs: 6\n",
      "  0 | 00:04:34 (274) |   9 |   20 |  -1.25% |  2.45% |  400 |  2.56% |   75\n",
      "  1 | 00:06:28 (114) |   3 |  250 |  -2.33% |  0.93% |   75 |  0.70% |   75\n",
      "  2 | 00:09:14 (167) |   5 |  500 |  -0.68% |  2.14% |   50 |  1.93% |   25\n",
      "  3 | 00:11:10 (116) |   3 |   20 |  -2.33% |  0.93% |   75 |  0.70% |   75\n",
      "  4 | 00:15:35 (264) |   9 |  250 |  -1.27% |  2.44% |  400 |  2.57% |  200\n",
      "  5 | 00:19:04 (209) |   7 |  250 |  -1.21% |  2.29% |   75 |  2.75% |   50\n",
      "  6 | 00:21:46 (163) |   5 |  250 |  -0.68% |  2.14% |   50 |  1.93% |   25\n",
      "  7 | 00:26:18 (272) |   9 |  500 |  -1.11% |  2.42% |  200 |  2.74% |  100\n",
      "  8 | 00:29:48 (209) |   7 |  500 |  -1.12% |  2.29% |   75 |  2.49% |   50\n",
      "  9 | 00:32:30 (162) |   5 |   20 |  -0.68% |  2.14% |   50 |  1.93% |   25\n",
      " 10 | 00:36:03 (213) |   7 |   20 |  -1.12% |  2.29% |   75 |  2.49% |   50\n",
      " 11 | 00:38:01 (117) |   3 |  500 |  -2.33% |  0.93% |   75 |  0.70% |   75\n",
      "Lookahead: 21 | Train: 1134 | Test: 63 | Params:  12 | Train configs: 6\n",
      "  0 | 00:04:30 (270) |   3 |   20 |  -2.08% |  1.95% |   50 |  3.78% |   50\n",
      "  1 | 00:10:53 (383) |   5 |  500 |  -6.66% |  0.84% |  1000 |  4.01% |  400\n",
      "  2 | 00:15:18 (265) |   3 |  500 |  -2.08% |  1.95% |   50 |  3.78% |   50\n",
      "  3 | 00:23:02 (464) |   7 |   20 |   8.16% |  2.56% |  1000 |  3.68% |  1000\n",
      "  4 | 00:32:26 (563) |   9 |  500 |   4.83% |  1.42% |   10 |  1.40% |  300\n",
      "  5 | 00:40:08 (462) |   7 |  250 |   9.42% |  2.99% |  400 |  4.34% |  200\n",
      "  6 | 00:46:31 (383) |   5 |  250 |  -6.44% |  0.83% |  1000 |  3.74% |  300\n",
      "  7 | 00:55:26 (535) |   9 |   20 |   4.90% |  2.40% |   50 |  1.90% |   50\n",
      "  8 | 01:04:23 (537) |   9 |  250 |   5.66% |  3.18% |   50 |  3.76% |   50\n",
      "  9 | 01:08:41 (258) |   3 |  250 |  -2.20% |  1.95% |   50 |  3.78% |   50\n",
      " 10 | 01:16:05 (444) |   7 |  500 |   9.26% |  2.17% |  200 |  3.09% |  200\n",
      " 11 | 01:22:22 (377) |   5 |   20 |  -2.35% |  1.56% |  1000 |  4.49% |  300\n",
      "Lookahead: 21 | Train: 252 | Test: 63 | Params:  12 | Train configs: 6\n",
      "  0 | 00:03:34 (214) |   7 |  500 |   3.32% |  1.13% |   50 |  1.85% |   25\n",
      "  1 | 00:08:17 (283) |   9 |   20 |   2.62% |  1.42% |   25 |  1.44% |   25\n",
      "  2 | 00:11:05 (168) |   5 |  500 |   3.80% |  2.34% |   10 |  2.59% |   10\n",
      "  3 | 00:13:51 (166) |   5 |  250 |   3.80% |  2.34% |   10 |  2.59% |   10\n",
      "  4 | 00:18:27 (276) |   9 |  500 |   2.57% |  1.45% |   25 |  1.47% |   25\n",
      "  5 | 00:23:04 (277) |   9 |  250 |   2.87% |  1.21% |   25 |  1.52% |   25\n",
      "  6 | 00:25:10 (125) |   3 |  250 |   1.56% |  3.48% |   50 |  3.21% |   50\n",
      "  7 | 00:27:53 (163) |   5 |   20 |   3.80% |  2.34% |   10 |  2.59% |   10\n",
      "  8 | 00:29:52 (118) |   3 |   20 |   1.56% |  3.48% |   50 |  3.21% |   50\n",
      "  9 | 00:31:52 (120) |   3 |  500 |   1.56% |  3.48% |   50 |  3.21% |   50\n",
      " 10 | 00:35:27 (215) |   7 |  250 |   3.32% |  1.13% |   50 |  1.85% |   25\n",
      " 11 | 00:39:02 (215) |   7 |   20 |   3.32% |  1.13% |   50 |  1.85% |   25\n"
     ]
    }
   ],
   "source": [
    "for lookahead, train_length, test_length in test_params:\n",
    "    cvp = np.random.choice(list(range(n_params)),\n",
    "                           size=int(n_params / 1),\n",
    "                           replace=False)\n",
    "    cv_params_ = [cv_params[i] for i in cvp]\n",
    "\n",
    "    n_splits = int(2 * YEAR / test_length)\n",
    "    print(f'Lookahead: {lookahead:2.0f} | Train: {train_length:3.0f} | '\n",
    "          f'Test: {test_length:2.0f} | Params: {len(cv_params_):3.0f} | Train configs: {len(test_params)}')\n",
    "\n",
    "    cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                              lookahead=lookahead,\n",
    "                              test_period_length=test_length,\n",
    "                              train_period_length=train_length)\n",
    "\n",
    "    label = label_dict[lookahead]\n",
    "    outcome_data = data.loc[:, features + [label]].dropna()\n",
    "    cat_cols_idx = [outcome_data.columns.get_loc(c) for c in categoricals]\n",
    "    catboost_data = Pool(label=outcome_data[label],\n",
    "                         data=outcome_data.drop(label, axis=1),\n",
    "                         cat_features=cat_cols_idx)\n",
    "    predictions, metrics, feature_importance, daily_ic = [], [], [], []\n",
    "    key = f'{lookahead}/{train_length}/{test_length}'\n",
    "    T = 0\n",
    "    for p, param_vals in enumerate(cv_params_):\n",
    "        params = dict(zip(param_names, param_vals))\n",
    "        # uncomment if running with GPU\n",
    "        params['task_type'] = 'GPU'\n",
    "\n",
    "        start = time()\n",
    "        cv_preds, nrounds = [], []\n",
    "        ic_cv = defaultdict(list)\n",
    "        for i, (train_idx, test_idx) in enumerate(cv.split(X=outcome_data)):\n",
    "            train_set = catboost_data.slice(train_idx.tolist())\n",
    "\n",
    "            model = CatBoostRegressor(**params)\n",
    "            model.fit(X=train_set,\n",
    "                      verbose_eval=False)\n",
    "\n",
    "            test_set = outcome_data.iloc[test_idx, :]\n",
    "            X_test = test_set.loc[:, model.feature_names_]\n",
    "            y_test = test_set.loc[:, label]\n",
    "            y_pred = {str(n): model.predict(X_test, ntree_end=n)\n",
    "                      for n in num_iterations}\n",
    "            cv_preds.append(y_test.to_frame(\n",
    "                'y_test').assign(**y_pred).assign(i=i))\n",
    "\n",
    "        cv_preds = pd.concat(cv_preds).assign(**params)\n",
    "        predictions.append(cv_preds)\n",
    "        by_day = cv_preds.groupby(level='date')\n",
    "        ic_by_day = pd.concat([by_day.apply(lambda x: spearmanr(x.y_test, x[str(n)])[0]).to_frame(n)\n",
    "                               for n in num_iterations], axis=1)\n",
    "        daily_ic_mean = ic_by_day.mean()\n",
    "        daily_ic_mean_n = daily_ic_mean.idxmax()\n",
    "        daily_ic_median = ic_by_day.median()\n",
    "        daily_ic_median_n = daily_ic_median.idxmax()\n",
    "\n",
    "        ic = [spearmanr(cv_preds.y_test, cv_preds[str(n)])[0]\n",
    "              for n in num_iterations]\n",
    "        t = time() - start\n",
    "        T += t\n",
    "        metrics = pd.Series(list(param_vals) +\n",
    "                            [t, daily_ic_mean.max(), daily_ic_mean_n,\n",
    "                             daily_ic_median.max(), daily_ic_median_n] + ic,\n",
    "                            index=metric_cols)\n",
    "        msg = f'{p:3.0f} | {format_time(T)} ({t:3.0f}) | {params[\"max_depth\"]:3.0f} | {params[\"min_child_samples\"]:4.0f} | '\n",
    "        msg += f' {max(ic):6.2%} | {ic_by_day.mean().max(): 6.2%} | {daily_ic_mean_n: 4.0f} | {ic_by_day.median().max(): 6.2%} | {daily_ic_median_n: 4.0f}'\n",
    "        print(msg)\n",
    "        metrics.to_hdf(cb_store, 'metrics/' + key)\n",
    "        ic_by_day.assign(**params).to_hdf(cb_store, 'daily_ic/' + key)\n",
    "        cv_preds.to_hdf(cb_store, 'predictions/' + key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml4t]",
   "language": "python",
   "name": "conda-env-ml4t-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "292.031px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
