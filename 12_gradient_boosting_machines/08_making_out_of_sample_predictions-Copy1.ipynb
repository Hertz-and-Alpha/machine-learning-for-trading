{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long-Short Strategy, Part 5: Generating out-of-sample predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll start designing, implementing, and evaluating a trading strategy for US equities driven by daily return forecasts produced by gradient boosting models.\n",
    "\n",
    "As in the previous examples, we'll lay out a framework and build a specific example that you can adapt to run your own experiments. There are numerous aspects that you can vary, from the asset class and investment universe to more granular aspects like the features, holding period, or trading rules. See, for example, the **Alpha Factor Library** in the [Appendix](../24_alpha_factor_library) for numerous additional features.\n",
    "\n",
    "We'll keep the trading strategy simple and only use a single ML signal; a real-life application will likely use multiple signals from different sources, such as complementary ML models trained on different datasets or with different lookahead or lookback periods. It would also use sophisticated risk management, from simple stop-loss to value-at-risk analysis.\n",
    "\n",
    "**Six notebooks** cover our workflow sequence:\n",
    "\n",
    "1. [preparing_the_model_data](04_preparing_the_model_data.ipyny): we engineer a few simple features from the Quandl Wiki data \n",
    "2. [trading_signals_with_lightgbm_and_catboost](05_trading_signals_with_lightgbm_and_catboost.ipynb): we tune hyperparameters for LightGBM and CatBoost to select a model, using 2015/16 as our validation period. \n",
    "3. [evaluate_trading_signals](06_evaluate_trading_signals): we compare the cross-validation performance using various metrics to select the best model. \n",
    "4. [model_interpretation](07_model_interpretation.ipynb): we take a closer look at the drivers behind the best model's predictions.\n",
    "5. `making_out_of_sample_predictions` (this noteboook): we predict returns for our out-of-sample period 2017.\n",
    "6. [backtesting_with_zipline](09_backtesting_with_zipline.ipynb): evaluate the historical performance of a long-short strategy based on our predictive signals using Zipline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:22.754238Z",
     "start_time": "2021-04-16T03:59:22.751670Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T05:08:44.486465Z",
     "start_time": "2021-04-16T05:08:44.469578Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from time import time\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import lightgbm as lgb\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:23.584097Z",
     "start_time": "2021-04-16T03:59:23.581416Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from utils import MultipleTimeSeriesCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:23.598076Z",
     "start_time": "2021-04-16T03:59:23.585119Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:23.611324Z",
     "start_time": "2021-04-16T03:59:23.598945Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "YEAR = 252\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:23.618708Z",
     "start_time": "2021-04-16T03:59:23.612249Z"
    }
   },
   "outputs": [],
   "source": [
    "scope_params = ['lookahead', 'train_length', 'test_length']\n",
    "daily_ic_metrics = ['daily_ic_mean', 'daily_ic_mean_n', 'daily_ic_median', 'daily_ic_median_n']\n",
    "lgb_train_params = ['learning_rate', 'num_leaves', 'feature_fraction', 'min_data_in_leaf']\n",
    "catboost_train_params = ['max_depth', 'min_child_samples']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate LightGBM predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:23.626636Z",
     "start_time": "2021-04-16T03:59:23.620602Z"
    }
   },
   "outputs": [],
   "source": [
    "base_params = dict(boosting='gbdt',\n",
    "                   objective='regression',\n",
    "                   verbose=-1)\n",
    "\n",
    "categoricals = ['year', 'month', 'sector', 'weekday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:23.637221Z",
     "start_time": "2021-04-16T03:59:23.627969Z"
    }
   },
   "outputs": [],
   "source": [
    "lookahead = 1\n",
    "store = Path('data/predictions.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:24.861291Z",
     "start_time": "2021-04-16T03:59:23.638248Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_hdf('data.h5', 'model_data').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:24.872441Z",
     "start_time": "2021-04-16T03:59:24.862170Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = sorted(data.filter(like='_fwd').columns)\n",
    "features = data.columns.difference(labels).tolist()\n",
    "label = f'r{lookahead:02}_fwd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:25.603772Z",
     "start_time": "2021-04-16T03:59:24.873415Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.loc[idx[:, '2010':], features + [label]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:25.670973Z",
     "start_time": "2021-04-16T03:59:25.604625Z"
    }
   },
   "outputs": [],
   "source": [
    "for feature in categoricals:\n",
    "    data[feature] = pd.factorize(data[feature], sort=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:25.743036Z",
     "start_time": "2021-04-16T03:59:25.671795Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb_data = lgb.Dataset(data=data[features],\n",
    "                       label=data[label],\n",
    "                       categorical_feature=categoricals,\n",
    "                       free_raw_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:25.860485Z",
     "start_time": "2021-04-16T03:59:25.743923Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb_ic = pd.read_hdf('data/model_tuning.h5', 'lgb/ic')\n",
    "lgb_daily_ic = pd.read_hdf('data/model_tuning.h5', 'lgb/daily_ic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T03:59:25.863322Z",
     "start_time": "2021-04-16T03:59:25.861312Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_lgb_params(data, t=5, best=0):\n",
    "    param_cols = scope_params[1:] + lgb_train_params + ['boost_rounds']\n",
    "    df = data[data.lookahead==t].sort_values('ic', ascending=False).iloc[best]\n",
    "    return df.loc[param_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:42:08.945191Z",
     "start_time": "2021-04-16T03:59:25.864181Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Position: 00\n",
      "1 2 3 4 \n",
      "Position: 01\n",
      "1 2 3 4 \n",
      "Position: 02\n",
      "1 2 3 4 \n",
      "Position: 03\n",
      "1 2 3 4 \n",
      "Position: 04\n",
      "1 2 3 4 \n",
      "Position: 05\n",
      "1 2 3 4 \n",
      "Position: 06\n",
      "1 2 3 4 \n",
      "Position: 07\n",
      "1 2 3 4 \n",
      "Position: 08\n",
      "1 2 3 4 \n",
      "Position: 09\n",
      "1 2 3 4                 0           1           2           3           4           5  \\\n",
      "count  252.000000  252.000000  252.000000  252.000000  252.000000  252.000000   \n",
      "mean     0.008746    0.010006    0.008341    0.013183    0.012268    0.007909   \n",
      "std      0.113957    0.112864    0.114705    0.110489    0.112048    0.114766   \n",
      "min     -0.329860   -0.327394   -0.333696   -0.325931   -0.323367   -0.346578   \n",
      "25%     -0.065093   -0.061371   -0.067849   -0.060716   -0.062146   -0.072207   \n",
      "50%      0.000489   -0.000011    0.000546   -0.000955    0.004078    0.001759   \n",
      "75%      0.079396    0.080209    0.077403    0.077787    0.074018    0.078712   \n",
      "max      0.348164    0.340111    0.339379    0.335639    0.354948    0.327248   \n",
      "\n",
      "                6           7           8           9  \n",
      "count  252.000000  252.000000  252.000000  252.000000  \n",
      "mean     0.011568    0.002824    0.007092    0.001946  \n",
      "std      0.112329    0.124192    0.115434    0.125084  \n",
      "min     -0.319395   -0.333735   -0.347080   -0.340187  \n",
      "25%     -0.061988   -0.075180   -0.069696   -0.076271  \n",
      "50%      0.002934    0.000511    0.003394   -0.000561  \n",
      "75%      0.077395    0.079207    0.075803    0.076675  \n",
      "max      0.336759    0.375935    0.335104    0.387399  \n"
     ]
    }
   ],
   "source": [
    "for position in range(10):\n",
    "    params = get_lgb_params(lgb_daily_ic,\n",
    "                            t=lookahead,\n",
    "                            best=position)\n",
    "\n",
    "    params = params.to_dict()\n",
    "\n",
    "    for p in ['min_data_in_leaf', 'num_leaves']:\n",
    "        params[p] = int(params[p])\n",
    "    train_length = int(params.pop('train_length'))\n",
    "    test_length = int(params.pop('test_length'))\n",
    "    num_boost_round = int(params.pop('boost_rounds'))\n",
    "    params.update(base_params)\n",
    "\n",
    "    print(f'\\nPosition: {position:02}')\n",
    "\n",
    "    # 1-year out-of-sample period\n",
    "    n_splits = int(YEAR / test_length)\n",
    "    cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                              test_period_length=test_length,\n",
    "                              lookahead=lookahead,\n",
    "                              train_period_length=train_length)\n",
    "\n",
    "    predictions = []\n",
    "    start = time()\n",
    "    for i, (train_idx, test_idx) in enumerate(cv.split(X=data), 1):\n",
    "        print(i, end=' ', flush=True)\n",
    "        lgb_train = lgb_data.subset(used_indices=train_idx.tolist(),\n",
    "                                    params=params).construct()\n",
    "\n",
    "        model = lgb.train(params=params,\n",
    "                          train_set=lgb_train,\n",
    "                          num_boost_round=num_boost_round,\n",
    "                          verbose_eval=False)\n",
    "\n",
    "        test_set = data.iloc[test_idx, :]\n",
    "        y_test = test_set.loc[:, label].to_frame('y_test')\n",
    "        y_pred = model.predict(test_set.loc[:, model.feature_name()])\n",
    "        predictions.append(y_test.assign(prediction=y_pred))\n",
    "\n",
    "    if position == 0:\n",
    "        test_predictions = (pd.concat(predictions)\n",
    "                            .rename(columns={'prediction': position}))\n",
    "    else:\n",
    "        test_predictions[position] = pd.concat(predictions).prediction\n",
    "\n",
    "by_day = test_predictions.groupby(level='date')\n",
    "for position in range(10):\n",
    "    if position == 0:\n",
    "        ic_by_day = by_day.apply(lambda x: spearmanr(\n",
    "            x.y_test, x[position])[0]).to_frame()\n",
    "    else:\n",
    "        ic_by_day[position] = by_day.apply(\n",
    "            lambda x: spearmanr(x.y_test, x[position])[0])\n",
    "print(ic_by_day.describe())\n",
    "test_predictions.to_hdf(store, f'lgb/test/{lookahead:02}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate CatBoost predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:47:49.952398Z",
     "start_time": "2021-04-16T04:47:49.946516Z"
    }
   },
   "outputs": [],
   "source": [
    "lookaheads = [1, 5, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:47:50.159085Z",
     "start_time": "2021-04-16T04:47:50.155503Z"
    }
   },
   "outputs": [],
   "source": [
    "label_dict = dict(zip(lookaheads, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:42:21.239471Z",
     "start_time": "2021-04-16T04:42:21.237509Z"
    }
   },
   "outputs": [],
   "source": [
    "lookahead = 1\n",
    "store = Path('data/predictions.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:42:33.046167Z",
     "start_time": "2021-04-16T04:42:30.939809Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_hdf('data.h5', 'model_data').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:42:33.057677Z",
     "start_time": "2021-04-16T04:42:33.047222Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = sorted(data.filter(like='_fwd').columns)\n",
    "features = data.columns.difference(labels).tolist()\n",
    "label = f'r{lookahead:02}_fwd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:42:34.147080Z",
     "start_time": "2021-04-16T04:42:33.058841Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.loc[idx[:, '2010':], features + [label]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:42:34.278518Z",
     "start_time": "2021-04-16T04:42:34.148155Z"
    }
   },
   "outputs": [],
   "source": [
    "for feature in categoricals:\n",
    "    data[feature] = pd.factorize(data[feature], sort=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:49:29.805949Z",
     "start_time": "2021-04-16T04:49:29.799821Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_cols_idx = [data.columns.get_loc(c) for c in categoricals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T04:49:31.122802Z",
     "start_time": "2021-04-16T04:49:30.128972Z"
    }
   },
   "outputs": [],
   "source": [
    "catboost_data = Pool(label=data[label],\n",
    "                     data=data.drop(label, axis=1),\n",
    "                     cat_features=cat_cols_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T05:07:56.282852Z",
     "start_time": "2021-04-16T05:07:56.226707Z"
    }
   },
   "outputs": [],
   "source": [
    "catboost_ic = pd.read_hdf('data/model_tuning.h5', 'catboost/ic')\n",
    "catboost_ic_avg = pd.read_hdf('data/model_tuning.h5', 'catboost/daily_ic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T05:07:57.137679Z",
     "start_time": "2021-04-16T05:07:57.135665Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cb_params(data, t=5, best=0):\n",
    "    param_cols = scope_params[1:] + catboost_train_params + ['boost_rounds']\n",
    "    df = data[data.lookahead==t].sort_values('ic', ascending=False).iloc[best]\n",
    "    return df.loc[param_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T05:09:16.726292Z",
     "start_time": "2021-04-16T05:08:48.185974Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Position: 00\n",
      "1 <catboost.core.CatBoostRegressor object at 0x00000213A46136A0>\n",
      "2 <catboost.core.CatBoostRegressor object at 0x00000213A45F8CD0>\n",
      "3 <catboost.core.CatBoostRegressor object at 0x00000213A4613670>\n",
      "4 <catboost.core.CatBoostRegressor object at 0x00000213A41F8670>\n",
      "\n",
      "Position: 01\n",
      "1 <catboost.core.CatBoostRegressor object at 0x00000213A45F27C0>\n",
      "2 <catboost.core.CatBoostRegressor object at 0x00000213A49E1760>\n",
      "3 <catboost.core.CatBoostRegressor object at 0x00000213A47CEB80>\n",
      "4 <catboost.core.CatBoostRegressor object at 0x00000213A49E1EB0>\n",
      "\n",
      "Position: 02\n",
      "1 <catboost.core.CatBoostRegressor object at 0x00000213A4613520>\n",
      "2 <catboost.core.CatBoostRegressor object at 0x00000213A49E18E0>\n",
      "3 <catboost.core.CatBoostRegressor object at 0x00000213A4613D00>\n",
      "4 <catboost.core.CatBoostRegressor object at 0x00000213A41F8670>\n",
      "\n",
      "Position: 03\n",
      "1 <catboost.core.CatBoostRegressor object at 0x00000213A4613820>\n",
      "2 <catboost.core.CatBoostRegressor object at 0x00000213A49D0A00>\n",
      "3 <catboost.core.CatBoostRegressor object at 0x00000213A45F8910>\n",
      "4 <catboost.core.CatBoostRegressor object at 0x00000213A49D09D0>\n",
      "\n",
      "Position: 04\n",
      "1 <catboost.core.CatBoostRegressor object at 0x00000213A49E1520>\n",
      "2 <catboost.core.CatBoostRegressor object at 0x00000213A45F2EB0>\n",
      "3 <catboost.core.CatBoostRegressor object at 0x00000213A49E1CA0>\n",
      "4 <catboost.core.CatBoostRegressor object at 0x00000213A4613E50>\n",
      "\n",
      "Position: 05\n",
      "1 <catboost.core.CatBoostRegressor object at 0x00000213A46E1700>\n",
      "2 <catboost.core.CatBoostRegressor object at 0x00000213A45F22E0>\n",
      "3 <catboost.core.CatBoostRegressor object at 0x00000213A49D0D30>\n",
      "4 <catboost.core.CatBoostRegressor object at 0x00000213A45F2520>\n",
      "\n",
      "Position: 06\n",
      "1 <catboost.core.CatBoostRegressor object at 0x00000213A41F8670>\n",
      "2 <catboost.core.CatBoostRegressor object at 0x00000213A49D03D0>\n",
      "3 <catboost.core.CatBoostRegressor object at 0x00000213A49E1520>\n",
      "4 <catboost.core.CatBoostRegressor object at 0x00000213A49D04C0>\n",
      "\n",
      "Position: 07\n",
      "1 <catboost.core.CatBoostRegressor object at 0x00000213A47CE100>\n",
      "2 <catboost.core.CatBoostRegressor object at 0x00000213A4613310>\n",
      "3 <catboost.core.CatBoostRegressor object at 0x00000213A45F25E0>\n",
      "4 <catboost.core.CatBoostRegressor object at 0x00000213A4613550>\n",
      "\n",
      "Position: 08\n",
      "1 <catboost.core.CatBoostRegressor object at 0x00000213A460D2B0>\n",
      "2 <catboost.core.CatBoostRegressor object at 0x00000213A49E1F40>\n",
      "3 <catboost.core.CatBoostRegressor object at 0x00000213A49D0D90>\n",
      "4 <catboost.core.CatBoostRegressor object at 0x00000213A45F8910>\n",
      "\n",
      "Position: 09\n",
      "1 <catboost.core.CatBoostRegressor object at 0x00000213A47BA3D0>\n",
      "2 <catboost.core.CatBoostRegressor object at 0x00000213A45F2E80>\n",
      "3 <catboost.core.CatBoostRegressor object at 0x00000213A47BA040>\n",
      "4 <catboost.core.CatBoostRegressor object at 0x00000213A45F22E0>\n",
      "                0           1           2           3           4           5  \\\n",
      "count  252.000000  252.000000  252.000000  252.000000  252.000000  252.000000   \n",
      "mean    -0.003113   -0.003426   -0.003113   -0.003426   -0.003118   -0.003122   \n",
      "std      0.140768    0.141401    0.140768    0.141401    0.140770    0.140773   \n",
      "min     -0.377710   -0.377710   -0.377710   -0.377710   -0.377710   -0.377710   \n",
      "25%     -0.098812   -0.103351   -0.098812   -0.103351   -0.098812   -0.098812   \n",
      "50%     -0.010505   -0.010505   -0.010505   -0.010505   -0.010505   -0.010505   \n",
      "75%      0.101483    0.105605    0.101483    0.105605    0.101483    0.101483   \n",
      "max      0.395167    0.395167    0.395167    0.395167    0.395167    0.395167   \n",
      "\n",
      "                6           7           8           9  \n",
      "count  252.000000  252.000000  252.000000  252.000000  \n",
      "mean    -0.005204   -0.005711   -0.005125   -0.005204  \n",
      "std      0.135086    0.136550    0.136310    0.135086  \n",
      "min     -0.388114   -0.388114   -0.388114   -0.388114  \n",
      "25%     -0.098020   -0.100445   -0.100294   -0.098020  \n",
      "50%     -0.000725   -0.001888   -0.002587   -0.000725  \n",
      "75%      0.084723    0.082715    0.084723    0.084723  \n",
      "max      0.409803    0.409803    0.409803    0.409803  \n"
     ]
    }
   ],
   "source": [
    "for position in range(10):\n",
    "    params = get_cb_params(catboost_ic_avg,\n",
    "                    t=lookahead,\n",
    "                    best=position)\n",
    "    \n",
    "    params = params.to_dict()\n",
    "    \n",
    "    for p in ['max_depth', 'min_child_samples']:\n",
    "        params[p] = int(params[p])\n",
    "    train_length = int(params.pop('train_length'))\n",
    "    test_length = int(params.pop('test_length'))\n",
    "    num_boost_round = int(params.pop('boost_rounds'))\n",
    "    params['task_type'] = 'GPU'\n",
    "\n",
    "    print(f'\\nPosition: {position:02}')\n",
    "    \n",
    "    # 1-year out-of-sample period\n",
    "    n_splits = int(YEAR / test_length)\n",
    "    cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                              test_period_length=test_length,\n",
    "                              lookahead=lookahead,\n",
    "                              train_period_length=train_length)\n",
    "\n",
    "    predictions = []\n",
    "    start = time()\n",
    "    for i, (train_idx, test_idx) in enumerate(cv.split(X=data), 1):\n",
    "        print(i, end=' ', flush=True)\n",
    "        train_set = catboost_data.slice(train_idx.tolist())\n",
    "\n",
    "        model = CatBoostRegressor(**params)\n",
    "        model.fit(X=train_set,\n",
    "                  verbose_eval=False)\n",
    "\n",
    "        test_set = data.iloc[test_idx, :]\n",
    "        y_test = test_set.loc[:, label].to_frame('y_test')\n",
    "        print(model)\n",
    "#         print(model.feature_names_)\n",
    "        \n",
    "        y_pred = model.predict(test_set.loc[:, model.feature_names_])\n",
    "        predictions.append(y_test.assign(prediction=y_pred))\n",
    "\n",
    "    if position == 0:\n",
    "        test_predictions = (pd.concat(predictions)\n",
    "                            .rename(columns={'prediction': position}))\n",
    "    else:\n",
    "        test_predictions[position] = pd.concat(predictions).prediction\n",
    "\n",
    "by_day = test_predictions.groupby(level='date')\n",
    "for position in range(10):\n",
    "    if position == 0:\n",
    "        ic_by_day = by_day.apply(lambda x: spearmanr(x.y_test, x[position])[0]).to_frame()\n",
    "    else:\n",
    "        ic_by_day[position] = by_day.apply(lambda x: spearmanr(x.y_test, x[position])[0])\n",
    "print(ic_by_day.describe())\n",
    "test_predictions.to_hdf(store, f'catboost/test/{lookahead:02}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml4t]",
   "language": "python",
   "name": "conda-env-ml4t-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "301.861px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
